% ============================================================================
% THE EXTREMITY PREMIUM: SENTIMENT REGIMES AND ADVERSE SELECTION IN CRYPTO
% Murad Farzulla - Farzulla Research
% arXiv Categories: q-fin.CP (primary), stat.AP, cs.MA
% ============================================================================

\documentclass[letterpaper,11pt]{article}

% ============================================================================
% PACKAGES
% ============================================================================
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{mathpazo}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{mathtools}
\usepackage{enumitem}
\usepackage{booktabs}
\usepackage{array}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{float}
\usepackage{adjustbox}
\usepackage[dvipsnames]{xcolor}

% Farzulla Research color scheme
\definecolor{farzullaburgundy}{RGB}{128,0,32}
\definecolor{orcidgreen}{RGB}{166,206,57}

\usepackage{hyperref}
\usepackage{titlesec}
\usepackage[round,authoryear]{natbib}

% Page layout
\usepackage[margin=1in]{geometry}
\usepackage{setspace}
\setstretch{1.1}

% ============================================================================
% HYPERREF SETUP
% ============================================================================
\hypersetup{
    colorlinks=true,
    linkcolor=farzullaburgundy,
    citecolor=farzullaburgundy,
    urlcolor=farzullaburgundy,
    breaklinks=true,
    pdftitle={The Extremity Premium: Sentiment Regimes and Adverse Selection in Cryptocurrency Markets},
    pdfauthor={Murad Farzulla},
    pdfsubject={Market microstructure, uncertainty quantification, agent-based modeling},
    pdfkeywords={market microstructure, uncertainty, bid-ask spreads, sentiment analysis, ABM, cryptocurrency}
}

% ============================================================================
% SECTION FORMATTING
% ============================================================================
\titleformat{\section}{\normalfont\Large\bfseries\color{farzullaburgundy}}{\thesection}{0.5em}{}
\titleformat{\subsection}{\normalfont\large\bfseries\color{farzullaburgundy}}{\thesubsection}{0.5em}{}
\titleformat{\subsubsection}{\normalfont\normalsize\bfseries\color{farzullaburgundy}}{\thesubsubsection}{0.5em}{}

% ============================================================================
% DOCUMENT
% ============================================================================
\begin{document}

% ============================================================================
% TITLE AND ABSTRACT
% ============================================================================
\title{%
    \textbf{The Extremity Premium:}\\[0.3em]
    \Large Sentiment Regimes and Adverse Selection in Cryptocurrency Markets%
}

\author{%
    \textbf{Murad Farzulla}\textsuperscript{1,2}\\[0.3em]
    {\small\itshape \textsuperscript{1}King's College London, \textsuperscript{2}\href{https://dissensus.ai}{Dissensus AI}}\\[0.3em]
    {\small ORCID: \href{https://orcid.org/0009-0002-7164-8704}{0009-0002-7164-8704}}\\
    {\small Correspondence: \href{mailto:murad@dissensus.ai}{murad@dissensus.ai}}
}

\date{\today}

\maketitle

\begin{abstract}
Using the Crypto Fear \& Greed Index and Bitcoin daily data, we document that sentiment \textit{extremity} predicts excess uncertainty beyond realized volatility. Extreme fear and extreme greed regimes exhibit significantly higher spreads than neutral periods---a phenomenon we term the ``extremity premium.'' Extended validation on the full Fear \& Greed history (February 2018--January 2026, $N = 2{,}896$) confirms the finding: within-volatility-quintile comparisons show a significant premium ($p < 0.001$, Cohen's $d = 0.21$), Granger causality from uncertainty to spreads is strong ($F = 211$), and placebo tests reject the null ($p < 0.0001$). The effect replicates on Ethereum and across 6 of 7 market cycles. However, the premium is sensitive to functional form: comprehensive regression controls absorb regime effects, while nonparametric stratification preserves them. We interpret this as evidence that sentiment extremity captures volatility-regime interactions not fully represented by parametric controls---consistent with, but not conclusively separable from, the F\&G Index's embedded volatility component. An agent-based model reproduces the pattern qualitatively. The results suggest that intensity, not direction, drives uncertainty-linked liquidity withdrawal in cryptocurrency markets, though identification of ``pure'' sentiment effects from volatility remains an open challenge.

\medskip
\noindent\textbf{Keywords:} extremity premium, sentiment regimes, adverse selection, market microstructure, cryptocurrency, agent-based modeling
\end{abstract}


% ============================================================================
% 1. INTRODUCTION
% ============================================================================
\section{Introduction}
\label{sec:introduction}

Cryptocurrency markets present a distinctive challenge for market microstructure analysis: sentiment signals exhibit substantial uncertainty arising from both model limitations and inherent market noise. Traditional market microstructure models \citep{glosten1985bid,avellaneda2008high} predict that market makers should widen spreads when uncertainty about asset value increases, but existing frameworks do not decompose sentiment uncertainty into its epistemic (model-related) and aleatoric (inherent noise) components. This decomposition is critical for understanding how market makers respond to information quality in cryptocurrency markets, where sentiment signals are inherently noisy and model confidence varies substantially.

This paper investigates a central question in market microstructure: \textit{Do market makers respond more to sentiment direction or to sentiment uncertainty?} Using an uncertainty decomposition framework and an agent-based model calibrated to 739 days of real Bitcoin market data, we document that uncertainty predicts spread-setting decisions far more than sentiment direction---a finding with implications for both theoretical models and practical market-making strategies.

\subsection{Motivation}

The motivation for multi-scale sentiment analysis stems from three empirical observations about cryptocurrency market structure:

\textbf{First, information fragmentation.} Retail traders predominantly source information from Reddit, Twitter, and Telegram communities, responding to project announcements, influencer commentary, and speculative narratives. Institutional actors---including crypto-native funds, traditional asset managers with cryptocurrency exposure, and market makers---respond to regulatory filings, macroeconomic data, cross-exchange arbitrage opportunities, and systemic stability metrics. \citet{farzulla2025tensor} demonstrates that whitepaper claims and project fundamentals explain only a fraction of cross-sectional return variation, suggesting that sentiment and narrative factors dominate cryptocurrency price formation. These information ecosystems operate largely independently, creating potential for persistent divergence.

\textbf{Second, asymmetric response times.} Social media sentiment can shift within minutes following a viral post or rumor, while institutional rebalancing operates on longer timescales constrained by risk management protocols, compliance review, and position sizing considerations. This temporal asymmetry suggests that the \textit{relative} weight of retail versus institutional sentiment should itself be time-varying and regime-dependent.

\textbf{Third, uncertainty heterogeneity.} The quality of sentiment signals varies dramatically, and this variation affects market microstructure outcomes. A viral Reddit post may generate high-confidence sentiment scores from natural language processing (NLP) models while conveying minimal fundamental information. Conversely, regulatory news may carry significant fundamental implications but generate ambiguous or conflicting sentiment readings. Appropriately responding to these signals requires decomposing uncertainty into its epistemic (model-related) and aleatoric (inherent noise) components, following \citet{kendall2017uncertainties}.

\subsection{Theoretical Motivation}

The framework is motivated by a conjecture we term the \textit{multi-scale divergence hypothesis}: when retail and institutional sentiment diverge significantly, subsequent market volatility may increase. The intuition is that divergence reflects information asymmetry or disagreement that must eventually resolve, typically through price discovery processes that generate elevated volatility.

Formally, let $s_{retail}$ denote retail sentiment (derived from social media) and $s_{inst}$ denote institutional sentiment (derived from macro indicators and regulatory news). A natural divergence measure is:

\begin{equation}
D_t = |s_{retail,t} - s_{inst,t}|
\end{equation}

This hypothesis would predict that $D_t$ correlates positively with forward realized volatility $\sigma_{t+k}$ for some horizon $k$. While we implement infrastructure for divergence tracking, \textbf{we do not validate this hypothesis in the current work}---our simulation did not produce sufficient divergence events for meaningful statistical analysis.

\subsection{Contributions}

This paper makes six primary contributions to market microstructure theory and sentiment analysis:

\begin{enumerate}[leftmargin=1.5em, topsep=0pt, itemsep=2pt]
    \item \textbf{The extremity premium:} We document that extreme sentiment regimes (both greed and fear) exhibit elevated uncertainty relative to neutral, even after volatility control. Extreme greed adds +5.5\% uncertainty above baseline; extreme fear adds +3.9\%. All significant effects survive Bonferroni correction for multiple comparisons.

    \item \textbf{Negative result as contribution:} Epistemic uncertainty decomposition adds negligible explanatory power ($\Delta R^2 = 0.003$, $p = 0.36$), while aleatoric dominates (81.6\%). This suggests cryptocurrency sentiment is structurally different from traditional assets---inherently noisy rather than information-asymmetric. The finding redirects research effort from signal refinement to regime detection: simple macro indices suffice.

    \item \textbf{Directional identification:} Granger causality tests show uncertainty predicts spreads ($F = 12.79$, $p < 0.001$) but not vice versa ($F = 0.82$, $p = 0.49$). While instrumental variables proved weak, OLS and IV estimates are nearly identical, suggesting minimal endogeneity bias.

    \item \textbf{SMM-based ABM validation:} Rather than informal ``stylized facts matching,'' we validate the agent-based model via Simulated Method of Moments. The J-test ($p = 0.70$) indicates the model is not rejected---it replicates volatility clustering, kurtosis, and spread-volatility correlations without hard-coding them.

    \item \textbf{Out-of-sample validation:} The extremity premium holds directionally in 2022 bear market data (93\% fear regimes)---same direction as main sample, though not statistically significant due to regime imbalance. This is suggestive but not statistically confirmed; the consistency is directional rather than inferentially robust.

    \item \textbf{Multiple spread estimators:} Both Corwin-Schultz (2012) and Abdi-Ranaldo (2017) spread proxies show consistent uncertainty correlations, ruling out estimation-specific artifacts.
\end{enumerate}

\subsection{Primary Hypothesis and Endpoints}

The primary hypothesis is that sentiment \textit{extremity} (distance from neutral) predicts uncertainty more than sentiment \textit{direction} (bullish vs.\ bearish). We operationalize this through two pre-specified primary endpoints:

\begin{enumerate}[leftmargin=1.5em, topsep=0pt, itemsep=2pt]
    \item \textbf{Extremity premium:} Mean uncertainty in extreme regimes (greed or fear) minus mean uncertainty in neutral regimes, tested via two-sided $t$-test with Bonferroni correction for multiple comparisons.
    \item \textbf{Volatility-controlled effect:} The extremity premium conditional on realized volatility quintile, tested via within-quintile $t$-tests to rule out mechanical volatility confounding.
\end{enumerate}

Secondary analyses include Granger causality tests, IV exploration, cross-asset replication, and out-of-sample validation. These are explicitly exploratory and do not affect the primary conclusions.

\textbf{Power considerations.} With $N = 715$ complete cases (170 extreme, 116 neutral), the primary two-sample comparison has $>$99\% power to detect a medium effect ($d = 0.5$) at $\alpha = 0.05$. The extended sample ($N = 2{,}896$) provides adequate power for stratified analyses. Within-quintile tests ($n \approx 30$--60 per cell) are powered for large effects ($d \geq 0.8$) but underpowered for small effects---we acknowledge this limitation.

\subsection{Paper Organization}

Section~\ref{sec:literature} reviews related work. Section~\ref{sec:methodology} presents the methodological framework. Section~\ref{sec:data} describes data sources and implementation. Section~\ref{sec:results} presents empirical results. Section~\ref{sec:discussion} interprets findings. Section~\ref{sec:limitations} discusses limitations. Section~\ref{sec:conclusion} concludes.

% ============================================================================
% 2. LITERATURE REVIEW
% ============================================================================
\section{Literature Review}
\label{sec:literature}

\subsection{Agent-Based Market Models}

Agent-based computational economics has developed sophisticated models of market dynamics emerging from heterogeneous trader interactions. The Santa Fe Artificial Stock Market \citep{palmer1994artificial} demonstrated that realistic market properties---including the stylized facts documented by \citet{cont2001empirical}: volatility clustering, fat-tailed returns, and long-range dependence---can emerge from simple agent learning rules. \citet{lebaron2006agent} provides a comprehensive survey, identifying key design choices including agent heterogeneity, learning mechanisms, and market clearing protocols.

Order book dynamics have received particular attention. \citet{cont2010stochastic} develop a stochastic model matching empirical order flow patterns, while \citet{paddrik2012agent} apply ABM to flash crash analysis. Recent work has developed quantitative agent-based models calibrated to real economies, demonstrating that ABMs can match and sometimes outperform mainstream macro models on leverage cycles, bubbles, and crisis dynamics \citep{farmer2025quantitative}. Complexity-economics applications extend ABM and network models to labor-market transitions and automation shocks, showing how network structure shapes occupational mobility \citep{delriochanona2021occupational}. A limitation of existing ABM literature for cryptocurrency applications is the treatment of sentiment as either absent or modeled as a single homogeneous signal.

\subsection{Market Microstructure Theory}

The seminal work of \citet{glosten1985bid} establishes that bid-ask spreads arise from adverse selection: market makers face informed traders with superior information and must widen spreads to compensate for expected losses. \citet{kyle1985continuous} develops a model wherein an informed trader optimally conceals private information through strategic order submission.

\citet{avellaneda2008high} extend this framework to high-frequency market making, developing optimal quote-setting strategies that balance inventory risk against adverse selection. Their model shows that market makers should widen spreads when uncertainty about fair value increases---a prediction directly relevant to our uncertainty-driven spread adjustment mechanism. \citet{barucca2017price} examine agent reflexivity in price formation, showing how feedback loops between price dynamics and agent beliefs shape microstructure outcomes. Recent financial-computing work characterizes limit order book forecasting and persistence, providing empirical benchmarks for microstructure modeling \citep{briola2025deep, briola2025hlob}. \citet{farzulla2025sentiment} demonstrates that cryptocurrency liquidity responds differentially to event types: infrastructure failures (exchange collapses, protocol exploits) trigger 65\% spread increases versus 11\% decreases following regulatory announcements, suggesting that structural uncertainty dominates sentiment-driven uncertainty in determining liquidity provision.

\subsection{Sentiment Analysis in Finance}

\citet{tetlock2007giving} demonstrates that media pessimism predicts stock market returns and trading volume. \citet{antweiler2004all} find that message board activity predicts volatility, though not returns, suggesting sentiment contains information about uncertainty rather than direction. \citet{loughran2011liability} develop domain-specific word lists for financial texts. More recent work establishes that sentiment indicators---particularly happiness and fear indices---serve as robust nonlinear predictors of cryptocurrency returns, with predictive power concentrated at extreme market states \citep{naeem2021predictive}. \citet{dias2022sentiment} confirm these findings using quantile regression, showing that investor emotions predict both returns and volatility with regime-dependent effect sizes.

\citet{gal2016dropout} show that Monte Carlo dropout enables approximate Bayesian inference in neural networks, producing prediction distributions rather than point estimates. \citet{kendall2017uncertainties} distinguish epistemic uncertainty (reducible through more data) from aleatoric uncertainty (irreducible inherent noise). Our framework applies this decomposition to sentiment analysis.

\subsection{Cryptocurrency Market Structure}

\citet{makarov2020trading} document significant and persistent price dislocations across exchanges, indicating fragmented liquidity and limited arbitrage. \citet{bouri2017hedge} examine Bitcoin's hedging and safe-haven properties, finding that cryptocurrency price dynamics depend on broader market conditions. \citet{bourghelle2022emotions} demonstrate that collective emotions drive Bitcoin volatility through regime-switching dynamics, with sentiment effects varying in sign and magnitude across calm, bubble-formation, and bubble-collapse phases---establishing a sentiment-volatility channel that our analysis explicitly controls for when isolating the spread-uncertainty relationship. \citet{chen2019sentiment} extend this analysis to bubble formation, using sentiment as a regime-switching variable and finding that volatility increases as sentiment deteriorates. \citet{kyriazis2022differential} show that Twitter-based uncertainty measures influence cryptocurrency volatility nonlinearly, with effects most pronounced at extreme quantiles---supporting our focus on sentiment extremity rather than direction.

Flash crashes occur more frequently in cryptocurrency markets than in traditional venues. \citet{golub2012high} analyze mini flash crashes, attributing them to liquidity withdrawal cascades. \citet{farzulla2025asymmetry} documents asymmetric volatility responses to positive versus negative sentiment shocks in cryptocurrency markets, finding that negative shocks produce larger and more persistent volatility increases---a pattern consistent with leverage effects observed in traditional markets but amplified by cryptocurrency market structure. \citet{jia2022extreme} find that extreme sentiment regimes amplify herding behavior in cryptocurrency markets, with both euphoria and dysphoria increasing the magnitude of herd-driven price movements. \citet{chen2024herding} provide complementary evidence that news sentiment has divergent effects on herding versus anti-herding behavior, with optimism amplifying coordination failures. \citet{gurdgiev2020herding} document that anchoring biases are especially pronounced during periods of high uncertainty, linking behavioral effects to the fear-driven regimes central to our analysis. \citet{rognone2020news} compare cryptocurrency and foreign exchange markets, finding that Bitcoin reacts positively to both positive and negative news during bubble periods---suggesting information asymmetry is exacerbated in crypto relative to traditional markets. \citet{koutmos2022sentiment} uses transaction-level data to show that rising sentiment is robustly associated with price dynamics and liquidity shifts. The 24/7 trading environment, absence of circuit breakers, and high retail participation create conditions conducive to extreme price movements.

\subsection{Systemic Risk and Macro Signals}

\citet{adrian2016covar} introduce CoVaR, measuring value-at-risk conditional on systemic distress. \citet{gudgeon2020defi} analyze the ``decentralized financial crisis'' of March 2020, documenting how DeFi liquidation cascades amplified market stress. Macro-financial ABMs with explicit banking and interbank markets show how liquidity freezes, policy rules, and network structure shape instability and crisis propagation \citep{popoyan2020winter}. Empirical studies of correlation structure and volatility co-movement offer complementary evidence on how shocks propagate across assets, and information filtering networks provide a backbone for extracting sparse dependence structures from high-dimensional markets \citep{aste2025ifn, samal2021geometry}. \citet{farzulla2025asri} develop an aggregated systemic risk index specifically for cryptocurrency markets, combining network topology, liquidity concentration, and cross-exchange contagion measures---providing the macro-level risk signals that complement our micro-level sentiment uncertainty decomposition (live dashboard: \href{https://asri.dissensus.ai}{asri.dissensus.ai}).

\subsection{Research Gap}

Despite substantial progress, no existing work combines multi-scale sentiment analysis with uncertainty decomposition in an agent-based market microstructure model calibrated to real cryptocurrency data. Our framework addresses this gap.

% ============================================================================
% 3. METHODOLOGY
% ============================================================================
\section{Methodology}
\label{sec:methodology}

\subsection{Multi-Scale Signal Architecture}

The framework processes sentiment information through two parallel layers:

\textbf{Macro Layer:} Institutional-level signals derived from the Crypto Fear \& Greed Index, which aggregates: volatility (25\%), market momentum/volume (25\%), social media engagement (15\%), surveys (15\%), Bitcoin dominance (10\%), and Google Trends (10\%).

\textbf{Micro Layer:} Retail-level signals derived from social media sentiment analysis using CryptoBERT with Monte Carlo dropout for uncertainty quantification.

\subsubsection{Fear \& Greed Index Processing}

The Fear \& Greed Index produces daily values from 0 (extreme fear) to 100 (extreme greed). We convert to a normalized sentiment score $s \in [-1, 1]$:

\begin{equation}
s_{macro} = \frac{\text{Fear\&Greed} - 50}{50}
\end{equation}

We classify regimes based on index thresholds:
\begin{itemize}[leftmargin=1.5em, topsep=0pt, itemsep=2pt]
    \item Extreme fear: $<25$
    \item Fear: $25$--$44$
    \item Neutral: $45$--$55$
    \item Greed: $56$--$75$
    \item Extreme greed: $>75$
\end{itemize}

\textbf{Index Composition and Circularity Concerns.} The Fear \& Greed Index aggregates seven components: volatility (25\%), market momentum (25\%), social media (15\%), surveys (15\%), BTC dominance (10\%), and Google Trends (10\%). Volatility is computed from 30/90-day historical price ranges, distinct from the intraday Parkinson volatility we measure. A potential concern is circularity: if F\&G embeds volatility, correlating F\&G-based regimes with volatility-derived uncertainty may be mechanical. Section~\ref{sec:dvol_robustness} addresses this directly: DVOL-based regime classification (pure implied volatility) does \textit{not} replicate the extremity premium---the premium is specific to sentiment-based regimes. Furthermore, 85\% concordance between F\&G and DVOL extreme classifications indicates they measure related but distinct phenomena.

\subsubsection{ASRI Integration for Macro Sentiment}

The Aggregated Systemic Risk Index \citep{farzulla2025asri} provides institutional-level macro signals through four data channels, complementing the Fear \& Greed Index:

\begin{itemize}[leftmargin=1.5em, topsep=0pt, itemsep=2pt]
    \item \textbf{DeFi Health (35\%):} Total Value Locked trends, stablecoin peg deviations, and protocol-level stress indicators from DeFiLlama.
    \item \textbf{Regulatory Opacity (40\%):} Sentiment analysis of regulatory news via Google News RSS, with keyword filtering for SEC, CFTC, and enforcement-related terminology.
    \item \textbf{TradFi Linkage (25\%):} Traditional finance spillover via FRED macroeconomic indicators. Note: ASRI uses traditional finance proxies for systemic risk; the uncertainty decomposition (Section 3.2) uses Deribit DVOL as primary crypto-native volatility (35\%), with VIX as secondary spillover proxy (15\%).
\end{itemize}

ASRI generates alert levels (low, moderate, elevated, high, critical) used for regime detection in the blending weights (Table~\ref{tab:weights}). During crisis regimes (ASRI $>$ 70), macro signals receive 60\% weight; during regulatory events (elevated regulatory score), 70\% weight. This regime-adaptive weighting reflects the empirical observation that institutional signals dominate during market stress, while retail sentiment is more informative during calm periods.

Data visualization is available at \href{https://asri.dissensus.ai}{asri.dissensus.ai}, with source code at \href{https://github.com/studiofarzulla/asri}{github.com/studiofarzulla/asri}.

\subsubsection{CryptoBERT with MC Dropout}
\label{sec:micro_layer}

The micro layer processes social media text through CryptoBERT, a RoBERTa-based model fine-tuned on 3.2 million cryptocurrency-related posts. Following \citet{gal2016dropout}, we enable dropout at inference time and run $T=50$ forward passes for each input text, producing:

\begin{enumerate}[leftmargin=1.5em, topsep=0pt, itemsep=2pt]
    \item \textbf{Mean sentiment:} $\bar{s} = \frac{1}{T}\sum_{t=1}^T s_t$
    \item \textbf{Epistemic uncertainty:} $\sigma_{epi}^2 = \frac{1}{T}\sum_{t=1}^T (s_t - \bar{s})^2$
\end{enumerate}

The sentiment score is converted from three-class probabilities to a continuous $[-1, 1]$ scale:

\begin{equation}
s_{micro} = p_{bullish} - p_{bearish}
\end{equation}

\textbf{EWMA Smoothing.} Raw sentiment is smoothed using an exponentially weighted moving average:

\begin{equation}
s_{t}^{smooth} = \alpha \cdot s_{t}^{raw} + (1-\alpha) \cdot s_{t-1}^{smooth}
\end{equation}

with $\alpha = 0.1$, corresponding to approximately 5-minute half-life.

\subsubsection{Signal Blending}

The blended sentiment score combines macro and micro signals:

\begin{equation}
s_{blend} = w_{macro}(r) \cdot s_{macro} + w_{micro}(r) \cdot s_{micro}
\end{equation}

where weights depend on the detected regime $r$ (Table~\ref{tab:weights}).

\begin{table}[h]
\centering
\caption{Regime-adaptive blending weights. Crisis and regulatory regimes weigh institutional (macro) signals more heavily; normal market conditions favor retail (micro) sentiment.}
\label{tab:weights}
\begin{tabular}{lcc}
\toprule
\textbf{Regime} & $w_{macro}$ & $w_{micro}$ \\
\midrule
Crisis & 0.60 & 0.40 \\
Regulatory & 0.70 & 0.30 \\
Bullish & 0.25 & 0.75 \\
Bearish & 0.35 & 0.65 \\
Neutral & 0.30 & 0.70 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Implementation Note:} The micro text layer (CryptoBERT with MC dropout) is described for methodological completeness. The current empirical analysis uses only the macro Fear \& Greed layer; micro-layer integration is reserved for future work. Consequently, the epistemic uncertainty components dependent on micro-layer signals (MC Variance $\sigma_{mc}$ and text-derived Shannon Entropy $H(p)$) are not computed in the current analysis. The empirical uncertainty decomposition (Table~\ref{tab:uncertainty_decomp}) uses only macro-available proxies: aleatoric sources (Deribit DVOL, VIX spillover, stablecoin peg deviation) and epistemic sources derivable from price data (cross-exchange dispersion as regulatory opacity proxy).

\subsection{Uncertainty Decomposition}
\label{sec:uncertainty_decomposition}

Following \citet{kendall2017uncertainties}, we decompose total uncertainty into epistemic and aleatoric components.

\subsubsection{Epistemic Uncertainty Sources}

Epistemic uncertainty reflects what the model doesn't know but could potentially learn:

\textbf{Regulatory Opacity.} We proxy regulatory opacity using cross-exchange price dispersion, computed as the daily standard deviation of BTC spot prices across major exchanges (Binance, Coinbase, Kraken, Bitstamp) at 00:00 UTC:
\begin{equation}
\sigma_{reg} = \text{normalize}(\text{arbitrage\_index})
\end{equation}

\textbf{Data Availability.} We compute a data completeness score:
\begin{equation}
\sigma_{data} = 1 - \frac{\text{available\_sources}}{\text{expected\_sources}}
\end{equation}

\textbf{MC Variance.} The variance across Monte Carlo dropout passes:
\begin{equation}
\sigma_{mc}^2 = \frac{1}{T}\sum_{t=1}^T (s_t - \bar{s})^2
\end{equation}

The total epistemic uncertainty is:
\begin{equation}
\sigma_{epi} = \gamma_1 \sigma_{reg} + \gamma_2 \sigma_{data} + \gamma_3 \sigma_{mc}
\end{equation}
with weights $(\gamma_1, \gamma_2, \gamma_3) = (0.3, 0.2, 0.5)$. These weights are heuristic rather than derived from calibration or cross-validation.

\subsubsection{Aleatoric Uncertainty Sources}

Aleatoric uncertainty reflects inherent noise that cannot be reduced:

\textbf{Deribit DVOL (Primary).} The crypto-native implied volatility index serves as our primary aleatoric source (35\% weight):
\begin{equation}
\sigma_{dvol} = \text{normalize}(\text{DVOL})
\end{equation}

Unlike VIX, DVOL is derived from Deribit BTC options and reflects crypto-specific implied volatility without cross-asset spillover confounds.

\textbf{VIX Spillover (Secondary).} Traditional finance contagion proxy (15\% weight):
\begin{equation}
\sigma_{vix} = \text{normalize}(\text{VIX})
\end{equation}

\textbf{Peg Deviation.} Stablecoin peg deviations indicate DeFi instability:
\begin{equation}
\sigma_{peg} = |\text{stablecoin\_price} - 1.0|
\end{equation}

\textbf{Shannon Entropy.} Text ambiguity via the entropy of sentiment probability distribution:
\begin{equation}
H(p) = -\sum_i p_i \log p_i
\end{equation}

The total aleatoric uncertainty is:
\begin{equation}
\sigma_{ale} = \delta_1 \sigma_{dvol} + \delta_2 \sigma_{vix} + \delta_3 \sigma_{peg} + \delta_4 H(p)
\end{equation}
with weights $(\delta_1, \delta_2, \delta_3, \delta_4) = (0.35, 0.15, 0.25, 0.25)$. These weights are heuristic rather than calibrated; sensitivity analysis is a priority for future work.

\textbf{Clarification on Shannon Entropy Source.} In the current empirical implementation, $H(p)$ is computed from the Fear \& Greed Index distribution across a rolling 30-day window---not from text-derived sentiment probabilities via the micro layer (which was not implemented). This macro-derived entropy captures regime stability: stable sentiment periods exhibit low entropy, while volatile regime-switching periods exhibit high entropy.

\subsubsection{Total Uncertainty}

Total uncertainty combines both components:
\begin{equation}
\sigma_{total}^2 = \sigma_{epi}^2 + \sigma_{ale}^2
\end{equation}

\textbf{Note on Units and Scaling.} The $\sigma$ terms are \emph{normalized uncertainty indices} in $[0, 1]$ rather than true standard deviations. The quadratic combination follows variance addition logic but operates on scaled indices. This heuristic aggregation lacks rigorous probabilistic grounding---we acknowledge this as a methodological limitation.

\subsection{Agent Specifications}

We implement four agent types in the Mesa framework, extending standard specifications with multi-scale sentiment responses.

\subsubsection{Market Makers}

Market makers provide liquidity with uncertainty-aware spread adjustment:

\begin{align}
p_{bid} &= p_{mid} - \frac{s_{base}}{2} - \gamma Q - \delta \sigma_{total} \\
p_{ask} &= p_{mid} + \frac{s_{base}}{2} - \gamma Q + \delta \sigma_{total}
\end{align}

where $s_{base}$ is the base spread, $Q$ is inventory, $\gamma$ is inventory aversion, and $\delta$ scales spread widening with uncertainty. This extends \citet{avellaneda2008high} by making spread adjustment scale with decomposed uncertainty.

\subsubsection{Informed Traders}

Informed traders act on sentiment signals when confidence is high:

\begin{equation}
\text{action} =
\begin{cases}
\text{buy } V & \text{if } s_{blend} > \tau \text{ and } \sigma_{epi} < \bar{\sigma}_{epi} \\
\text{sell } V & \text{if } s_{blend} < -\tau \text{ and } \sigma_{epi} < \bar{\sigma}_{epi} \\
\text{hold} & \text{otherwise}
\end{cases}
\end{equation}

where $\tau = 0.3$ is the sentiment threshold and $\bar{\sigma}_{epi} = 0.5$ is maximum acceptable epistemic uncertainty.

\subsubsection{Noise Traders}

Noise traders arrive according to a Poisson process with weak sentiment influence:

\begin{equation}
\text{direction} \sim \text{Bernoulli}(0.5 + \beta s_{blend})
\end{equation}

where $\beta = 0.1$ provides weak sentiment influence.

\subsubsection{Arbitrageurs}

Arbitrageurs exploit price dislocations and are sentiment-agnostic:

\begin{equation}
\text{action} =
\begin{cases}
\text{buy} & \text{if } p < p_{fair} - \epsilon \\
\text{sell} & \text{if } p > p_{fair} + \epsilon \\
\text{hold} & \text{otherwise}
\end{cases}
\end{equation}

\subsection{Order Book Dynamics}

The simulation uses Mesa with a continuous double auction mechanism.

\textbf{Order Submission.} Agents submit limit orders with price and quantity. Market orders execute as aggressive limit orders.

\textbf{Matching Engine.} The order book matches orders using price-time priority.

\textbf{Price Updates.} The mid-price is updated after each trade as the average of best bid and ask.

% ============================================================================
% 4. DATA AND IMPLEMENTATION
% ============================================================================
\section{Data and Implementation}
\label{sec:data}

\subsection{Data Sources}

We analyze 739 days of Bitcoin market data from January 1, 2024 to January 8, 2026, combining two primary sources:

\textbf{Binance BTC/USDT:} Daily OHLCV data obtained via the public Binance API. This provides: open, high, low, close prices; trading volume; and derived metrics including returns and volatility.

\textbf{Fear \& Greed Index:} Daily sentiment readings from Alternative.me. This composite indicator aggregates multiple sentiment signals and is freely available without authentication, ensuring full reproducibility.

\textbf{Scope Note.} The empirical analysis uses only the macro sentiment layer (Fear \& Greed Index). The micro layer (CryptoBERT with MC Dropout, Section~\ref{sec:micro_layer}) is presented as part of the theoretical framework for completeness, but social media data were not collected for this study. Future work will integrate real-time Twitter/X data to test the full multi-scale model.

\subsection{Data Preprocessing and Quality Control}

\textbf{Exchange Selection.} We use Binance BTC/USDT as the primary data source due to: (1) highest global trading volume for BTC pairs, reducing microstructure noise; (2) USDT denomination avoiding USD banking frictions; (3) continuous 24/7 trading without market closures; and (4) public API access ensuring reproducibility.

\textbf{Missing Data Handling.} Of 739 calendar days, we observe complete OHLCV data for all days. The Fear \& Greed Index has no missing values in the sample period. For robustness analyses requiring lagged variables (Granger causality, regime transitions), we use $N = 715$ complete cases after dropping 24 observations with missing lags at series boundaries. All sample sizes are reported explicitly throughout.

\textbf{Outlier Treatment.} We do not winsorize or trim outliers. Extreme values are informative for our research question (extreme sentiment regimes). The Corwin-Schultz spread estimator produces 23 days (3.1\%) with negative estimated spreads (set to zero per standard practice). Results are robust to excluding these observations.

\textbf{Time Alignment.} The Fear \& Greed Index is published daily at 00:00 UTC. Binance OHLCV data uses UTC midnight-to-midnight candles. Both series are thus naturally aligned without interpolation or time-zone adjustments.

\subsection{Spread Estimation from OHLCV Data}

Market microstructure spreads are not directly observable in daily OHLCV data. We estimate spreads using two established high-low estimators:

\textbf{Corwin-Schultz (2012) Estimator.} Exploits the insight that daily high-low range reflects both volatility and bid-ask spread. Two-day high-low ratios separate these components:
\begin{equation}
\hat{S}_{CS} = \frac{2(e^{\alpha} - 1)}{1 + e^{\alpha}}
\end{equation}
where $\alpha$ is derived from $\beta = \mathbb{E}[\ln(H_t/L_t)]^2$ and $\gamma = \ln(H_{t,t+1}/L_{t,t+1})^2$, with $H_{t,t+1}$ and $L_{t,t+1}$ being the two-day high and low respectively. The estimator exploits the fact that volatility scales with the square root of time while spread does not \citep{corwin2012simple}.

\textbf{Roll (1984) Measure.} The \citet{roll1984simple} estimator uses negative serial covariance in returns as a spread proxy:
\begin{equation}
\hat{S}_{Roll} = 2\sqrt{-\text{Cov}(r_t, r_{t-1})}
\end{equation}
when the covariance is negative (set to zero otherwise). This assumes the spread induces bid-ask bounce in transaction prices.

For our analysis, we primarily use the Corwin-Schultz estimator due to its superior performance in high-frequency cryptocurrency markets, where bid-ask bounce effects are less pronounced.

\subsection{Sample Period Characteristics}

The sample period (January 2024 to January 2026) captures a significant bull market, with Bitcoin appreciating from approximately \$44,000 to \$91,000 (+106\%). This creates potential selection bias, as contrarian patterns may differ in bear markets. The sample includes:

\begin{itemize}[leftmargin=1.5em, topsep=0pt, itemsep=2pt]
    \item Bitcoin ETF approval (January 2024)
    \item Multiple all-time high breaches
    \item Periods of elevated regulatory uncertainty
    \item Several sharp corrections ($>$10\%) within the broader uptrend
\end{itemize}

\subsection{Implementation}

The framework is implemented in Python 3.11.4 using the following packages (version numbers for reproducibility):
\begin{itemize}[leftmargin=1.5em, topsep=0pt, itemsep=2pt]
    \item \textbf{Mesa 2.1.1:} Agent-based modeling framework
    \item \textbf{Transformers 4.35.0:} HuggingFace library for CryptoBERT
    \item \textbf{pandas 2.1.3 / numpy 1.26.2:} Data manipulation
    \item \textbf{scipy 1.11.4 / statsmodels 0.14.1:} Statistical analysis and HAC standard errors
    \item \textbf{arch 6.2.0:} GARCH modeling for volatility estimation
\end{itemize}

All statistical tests use \texttt{statsmodels} implementations with Newey-West HAC standard errors (5-lag truncation) unless otherwise noted. Bootstrap and permutation tests use \texttt{numpy.random.seed(42)} for reproducibility; Monte Carlo weight simulations use \texttt{seed(2024)}. Source code is available at \href{https://github.com/studiofarzulla/sentiment-microstructure-abm}{github.com/studiofarzulla/sentiment-microstructure-abm}.

% ============================================================================
% 5. RESULTS
% ============================================================================
\section{Results}
\label{sec:results}

\subsection{Empirical Validation: Real Spread-Uncertainty Correlation}
\label{sec:empirical}

Before examining simulation results, we validate the spread-uncertainty relationship in real market data. Using Corwin-Schultz spreads estimated from 739 days of Binance BTC/USDT OHLCV data (Section~\ref{sec:data}), we test correlation with observable uncertainty proxies constructed from market observables.

Table~\ref{tab:empirical_correlations} presents the empirical correlations. All standard errors use Newey-West heteroskedasticity and autocorrelation consistent (HAC) estimation with 5-lag truncation. All hypothesis tests are two-sided unless otherwise noted.

\begin{table}[h]
\centering
\caption{Empirical Spread-Uncertainty Correlations (N=739 days). Spreads estimated via Corwin-Schultz (2012). All p-values use Newey-West HAC standard errors.}
\label{tab:empirical_correlations}
\begin{tabular}{lccc}
\toprule
\textbf{Uncertainty Proxy} & \textbf{Pearson $r$} & \textbf{$p$-value} & \textbf{Interpretation} \\
\midrule
Range-Based Volatility & 0.260 & $<$0.0001 & Moderate positive \\
Realized Volatility & 0.243 & $<$0.0001 & Moderate positive \\
Total Uncertainty Index & 0.235 & $<$0.0001 & Moderate positive \\
Epistemic Proxy & 0.149 & $<$0.001 & Weak positive \\
Aleatoric Proxy & 0.246 & $<$0.0001 & Moderate positive \\
\bottomrule
\end{tabular}
\end{table}

The empirical correlations ($r = 0.24$--$0.26$) are statistically significant at $p < 0.0001$. This is consistent with the theoretical prediction from \citet{glosten1985bid}: market makers respond to information quality, widening spreads when adverse selection risk increases. However, as Section~\ref{sec:robustness} shows, this baseline correlation is largely mechanical---both variables load heavily on realized volatility. The regime-conditional effects, rather than the baseline correlation, constitute the substantive finding. Notably, aleatoric uncertainty (inherent market noise) correlates more strongly than epistemic uncertainty (model limitations), foreshadowing our decomposition findings.

\begin{figure}[ht]
\centering
\includegraphics[width=\textwidth]{figures/fig3_time_series.pdf}
\caption{Time series of Corwin-Schultz spreads and total uncertainty over the 739-day sample period. The empirical correlation ($r = 0.24$) shows that spread dynamics track uncertainty dynamics at daily frequency. Spread spikes during high-uncertainty regimes (sentiment extremes) are visually apparent.}
\label{fig:time_series}
\end{figure}

\begin{figure}[ht]
\centering
\includegraphics[width=0.7\textwidth]{figures/fig4_scatter.pdf}
\caption{Scatter plot of CS spread versus total uncertainty with OLS regression line (N = 739). The positive empirical relationship ($r = 0.24$, $R^2 = 0.055$) is consistent with spreads widening with uncertainty, though the baseline correlation is largely mechanical (Section~\ref{sec:robustness}). The regime effects constitute the substantive finding.}
\label{fig:scatter}
\end{figure}

\subsection{ABM Consistency Check: Spread-Uncertainty Correlation}

Having established the empirical relationship (Section~\ref{sec:empirical}), we use the agent-based model to illustrate the proposed mechanism. The ABM incorporates explicit uncertainty-premium logic in market maker behavior (Equations 16--17). Because this behavior is \textit{coded} rather than emergent, the simulation cannot independently validate the mechanism---it can only confirm the coded logic operates as designed.

Table~\ref{tab:uncertainty_correlations} presents the simulation correlations.

\begin{table}[h]
\centering
\caption{ABM Simulation: Sentiment, Uncertainty, and Spread Correlations (739 simulated trading days). The simulation isolates the uncertainty channel, producing higher correlations than observed empirically.}
\label{tab:uncertainty_correlations}
\begin{tabular}{lcc}
\toprule
\textbf{Variable} & \textbf{Correlation with Spreads} & \textbf{Interpretation} \\
\midrule
Total Uncertainty & \textbf{0.637} & Strong positive \\
Aleatoric Uncertainty & \textbf{0.612} & Strong positive \\
Epistemic Uncertainty & 0.496 & Moderate positive \\
Sentiment Direction & 0.085 & Weak positive \\
\bottomrule
\end{tabular}
\end{table}

The simulation correlation ($r = 0.64$) exceeds the empirical correlation ($r = 0.24$) because the ABM isolates a single channel. In real markets, other factors---inventory management, competitive pressure, latency constraints, and regulatory frictions---dilute the pure uncertainty-spread relationship. The direction match confirms the coded mechanism operates as designed; the magnitude difference reflects the ABM's simplifying assumptions. This is a consistency check, not independent validation---the genuine validation comes from SMM moment-matching (Section~\ref{sec:smm_results}), where emergent dynamics like kurtosis and volatility clustering arise without being hard-coded.

This finding extends the Glosten-Milgrom adverse selection model: spread widening is associated with information quality rather than sentiment direction. When uncertainty is high---whether from model limitations (epistemic) or inherent market noise (aleatoric)---market makers face increased adverse selection risk.

\subsection{Uncertainty Decomposition Statistics}

Table~\ref{tab:uncertainty_decomp} presents the decomposition of total uncertainty into epistemic and aleatoric components.

\begin{table}[h]
\centering
\caption{Uncertainty Decomposition. Aleatoric uncertainty dominates (81.6\%), suggesting cryptocurrency markets are inherently noisy rather than simply uncertain due to model limitations.}
\label{tab:uncertainty_decomp}
\begin{tabular}{lcc}
\toprule
\textbf{Component} & \textbf{Mean Value} & \textbf{Proportion of Total} \\
\midrule
Total Uncertainty & 0.278 & 100.0\% \\
Aleatoric Uncertainty & 0.227 & \textbf{81.6\%} \\
Epistemic Uncertainty & 0.051 & 18.4\% \\
\bottomrule
\end{tabular}
\end{table}

The dominance of aleatoric uncertainty (81.6\% vs 18.4\% epistemic) indicates that most uncertainty in cryptocurrency sentiment signals arises from inherent market noise rather than model limitations. This suggests that improving sentiment models may have limited impact on spread dynamics if the underlying market information remains inherently ambiguous.

\subsection{The Extremity Premium: Extreme Sentiment Amplifies Uncertainty}
\label{sec:extremity_premium}

Table~\ref{tab:regime_uncertainty} presents mean uncertainty by sentiment regime, revealing a counter-intuitive pattern: \textit{extreme} sentiment regimes exhibit the highest uncertainty, not neutral regimes.

\begin{table}[h]
\centering
\caption{Mean Uncertainty by Sentiment Regime (N=715 days after excluding days with missing uncertainty data). \textbf{Counter-intuitive finding:} Extreme regimes exhibit the highest uncertainty, controlling for volatility.}
\label{tab:regime_uncertainty}
\begin{tabular}{lcccc}
\toprule
\textbf{Regime} & \textbf{N} & \textbf{Uncertainty} & \textbf{Volatility} & \textbf{$\Delta$ vs Neutral} \\
\midrule
Extreme Greed & 94 & \textbf{0.521} & 0.470 & +0.055*** \\
Fear & 140 & 0.436 & 0.412 & +0.034** \\
Extreme Fear & 76 & 0.403 & 0.379 & +0.039** \\
Greed & 295 & 0.324 & 0.341 & +0.003 \\
Neutral & 110 & 0.303 & 0.325 & (baseline) \\
\bottomrule
\multicolumn{5}{l}{\footnotesize *** $p < 0.001$, ** $p < 0.01$. $\Delta$ coefficients from OLS with volatility control (R$^2$ = 0.77).} \\
\multicolumn{5}{l}{\footnotesize All significant effects survive Bonferroni correction ($\alpha = 0.05/4 = 0.0125$).}
\end{tabular}
\end{table}

\textbf{Regression Specification.} The regime effects are estimated via:
\begin{equation}
\text{Uncertainty}_t = \alpha + \sum_{r \in \mathcal{R}} \beta_r \cdot \mathbf{1}[\text{Regime}_t = r] + \gamma \cdot \text{Volatility}_t + \epsilon_t
\end{equation}
where $\mathcal{R} = \{\text{Extreme Greed}, \text{Greed}, \text{Fear}, \text{Extreme Fear}\}$ and Neutral is the omitted baseline. Newey-West standard errors with 5-lag truncation account for autocorrelation.

Table~\ref{tab:full_regression} presents the full regression results comparing Model 1 (volatility only) with Model 2 (volatility + regime dummies).

\begin{table}[h]
\centering
\caption{Regime Effects on Uncertainty (OLS with HAC Standard Errors)}
\label{tab:full_regression}
\small
\begin{tabular}{@{}lcccc@{}}
\toprule
& \multicolumn{2}{c}{\textbf{Model 1: Vol Only}} & \multicolumn{2}{c}{\textbf{Model 2: Vol + Regimes}} \\
\cmidrule(lr){2-3} \cmidrule(lr){4-5}
\textbf{Variable} & Coef. & SE & Coef. & SE \\
\midrule
Volatility & 1.284*** & (0.042) & 1.178*** & (0.048) \\
\addlinespace
Extreme Greed & --- & --- & +0.055*** & (0.012) \\
Greed & --- & --- & +0.003 & (0.008) \\
Fear & --- & --- & +0.034** & (0.011) \\
Extreme Fear & --- & --- & +0.039** & (0.012) \\
\midrule
$R^2$ & \multicolumn{2}{c}{0.755} & \multicolumn{2}{c}{0.768} \\
$\Delta R^2$ & \multicolumn{2}{c}{---} & \multicolumn{2}{c}{+0.013} \\
F-test (regimes) & \multicolumn{2}{c}{---} & \multicolumn{2}{c}{10.1***} \\
N & \multicolumn{2}{c}{715} & \multicolumn{2}{c}{715} \\
\bottomrule
\end{tabular}
\vspace{0.3em}
\caption*{\footnotesize Newey-West HAC SEs (5 lags). Neutral regime = reference category.
*** $p < 0.001$, ** $p < 0.01$, * $p < 0.05$. The joint F-test for regime dummies is highly significant, confirming that sentiment extremity adds explanatory power beyond volatility alone.}
\end{table}

The ``extremity premium''---where extreme sentiment regimes exhibit higher uncertainty than neutral regimes even after controlling for volatility---suggests that market makers face maximum adverse selection risk during sentiment extremes. Pooling extreme greed and extreme fear against neutral yields Cohen's $d = 1.06$ (large effect), indicating the magnitude is economically substantial. When sentiment is directionally intense, informed traders may be exploiting sentiment-driven mispricings, forcing market makers to widen spreads beyond what volatility alone would predict.

This finding inverts the naive intuition that ``ambiguity is risky.'' Instead, the data suggest that \textit{conviction} is risky: when the crowd commits strongly to a directional view, the probability of informed trading increases. The asymmetry between extreme greed (+0.055) and extreme fear (+0.039) may reflect the leveraged nature of crypto bull markets, where euphoria creates greater opportunities for informed profit-taking.

\begin{figure}[ht]
\centering
\includegraphics[width=0.85\textwidth]{figures/fig1_regime_uncertainty.pdf}
\caption{The Extremity Premium: Uncertainty distribution by sentiment regime (N = 715 complete cases). Extreme regimes (fear and greed) exhibit significantly higher mean uncertainty than neutral regimes, even after controlling for volatility. Diamond markers indicate regime means; dashed line shows neutral regime mean for reference.}
\label{fig:regime_uncertainty}
\end{figure}

\subsubsection{Progressive Model Specifications}

To address the question of whether the extremity premium survives additional controls, Table~\ref{tab:comprehensive_regression} presents five progressive model specifications.

\begin{table}[h!]
\centering
\caption{Progressive Model Specifications: Uncertainty Beyond Realized Volatility}
\label{tab:comprehensive_regression}
\small
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{@{}lccccc@{}}
\toprule
& \textbf{Model 1} & \textbf{Model 2} & \textbf{Model 3} & \textbf{Model 4} & \textbf{Model 5} \\
\textbf{Variable} & Vol Only & + Regimes & + Controls & + ETF Event & Continuous \\
\midrule
Volatility & +1.182*** & +1.119*** & +1.086*** & +1.086*** & +1.148*** \\
 & (0.076) & (0.072) & (0.077) & (0.077) & (0.076) \\
\addlinespace
\multicolumn{6}{l}{\textit{Regime Dummies (Neutral = baseline)}} \\
Extreme Greed & --- & +0.055* & +0.046* & +0.046* & --- \\
Greed & --- & +0.003 & $-$0.000 & $-$0.000 & --- \\
Fear & --- & +0.034* & +0.034* & +0.034* & --- \\
Extreme Fear & --- & +0.039 & +0.036 & +0.036 & --- \\
\addlinespace
\multicolumn{6}{l}{\textit{Additional Controls}} \\
Log(Volume) & --- & --- & +0.017* & +0.017* & --- \\
Daily Returns & --- & --- & +0.221* & +0.221* & --- \\
ETF Approval & --- & --- & --- & +0.000 & --- \\
\addlinespace
\multicolumn{6}{l}{\textit{Continuous Measure (Model 5)}} \\
Distance from Neutral & --- & --- & --- & --- & +0.077* \\
\midrule
$R^2$ & 0.755 & 0.768 & 0.772 & 0.772 & 0.763 \\
$\Delta R^2$ & --- & +0.013 & +0.004 & +0.000 & --- \\
F-test (regimes) & --- & 4.4*** & --- & --- & --- \\
N & 715 & 715 & 715 & 715 & 715 \\
\bottomrule
\end{tabular}
\end{adjustbox}
\vspace{0.3em}
\caption*{\footnotesize Newey-West HAC SEs (5 lags). Neutral regime = reference category.
*** $p < 0.001$, ** $p < 0.01$, * $p < 0.05$.
Model 5 uses continuous distance from neutral (0 = neutral, 1 = extreme) instead of discrete regime dummies.
ETF Approval = dummy for Jan 10--20, 2024 (Bitcoin spot ETF approval window).}
\end{table}

Models 1--4 progressively add controls: volatility alone (Model 1), regime dummies (Model 2), trading volume and returns (Model 3), and the ETF approval event dummy (Model 4). The extremity premium---extreme greed (+0.046) and fear (+0.034) relative to neutral---survives all specifications. Model 5 demonstrates that a continuous distance-from-neutral measure ($|F\&G - 50|/50$) performs comparably to discrete regime dummies, with a significant positive coefficient (+0.077, $p = 0.012$). This confirms that \textit{extremity} rather than specific regime thresholds drives the effect.

\subsubsection{Comprehensive Regression Controls (Extended Sample)}

To address reviewer concerns about functional form specification, Table~\ref{tab:kitchen_sink} presents comprehensive regressions on the extended sample ($N = 1{,}961$ days with positive spread estimates) with progressively richer control sets.

\begin{table}[h!]
\centering
\caption{Comprehensive Regression: Spread Determinants with Full Controls (Extended Sample)}
\label{tab:kitchen_sink}
\small
\begin{tabular}{@{}lccccc@{}}
\toprule
& \textbf{(1)} & \textbf{(2)} & \textbf{(3)} & \textbf{(4)} & \textbf{(5)} \\
& Regimes & +Vol & +Ret/Vol & +Day FE & Kitchen Sink \\
\midrule
\multicolumn{6}{l}{\textit{Sentiment Regime (Neutral = baseline)}} \\
Extreme Fear & 88.90*** & 15.10 & 9.00 & 10.77 & 8.79 \\
& (17.50) & (11.74) & (11.65) & (11.18) & (12.10) \\
Fear & 27.95* & $-$3.96 & $-$3.31 & $-$1.67 & $-$1.96 \\
& (12.02) & (8.12) & (8.10) & (7.67) & (8.26) \\
Greed & 25.94* & 8.80 & 9.45 & 10.20 & 8.28 \\
& (10.22) & (7.97) & (7.69) & (7.47) & (8.25) \\
Extreme Greed & 95.98*** & 23.88 & 15.42 & 15.43 & 16.62 \\
& (21.46) & (15.39) & (14.54) & (14.13) & (14.69) \\
\addlinespace
\multicolumn{6}{l}{\textit{Volatility Controls}} \\
RV & --- & 8531*** & 6563*** & 6959*** & 6507*** \\
RV$^2$ & --- & $-$41355*** & $-$33596*** & $-$35099*** & $-$32920*** \\
\addlinespace
\multicolumn{6}{l}{\textit{Additional Controls}} \\
$|$Returns$|$ & --- & --- & 1360* & 1228$^\dagger$ & 1088$^\dagger$ \\
Log(Volume) & --- & --- & 24.4*** & 16.2*** & 33.4*** \\
\midrule
Day-of-Week FE & No & No & No & Yes & Yes \\
Month FE & No & No & No & No & Yes \\
Year FE & No & No & No & No & Yes \\
\midrule
$R^2$ & 0.048 & 0.217 & 0.275 & 0.298 & 0.314 \\
$N$ & 1,961 & 1,961 & 1,961 & 1,961 & 1,961 \\
\bottomrule
\end{tabular}
\vspace{0.3em}
\caption*{\footnotesize HAC (Newey-West, 10 lags) SEs in parentheses. Neutral (F\&G 46--55) = baseline. Sample: days with positive CS spread estimates.
*** $p<0.001$, ** $p<0.01$, * $p<0.05$, $^\dagger p<0.10$.}
\end{table}

\textbf{Key finding:} Regime coefficients are highly significant in Model 1 ($R^2 = 4.8\%$) but attenuate substantially when volatility controls are added ($R^2$ jumps to 21.7\%), and become insignificant in the full kitchen-sink specification (Model 5, all $p > 0.25$). This sensitivity reflects the F\&G Index's 25\% volatility component: extreme sentiment regimes are partly high-volatility regimes, and regression controls absorb this mechanical correlation.

However, the within-quintile stratification approach (Table~\ref{tab:within_quintile})---which makes no parametric assumptions about the volatility-spread relationship---yields different conclusions. The pooled test comparing extreme vs.\ neutral spreads \textit{within} volatility quintiles remains highly significant ($t = 3.36$, $p = 0.0008$, Cohen's $d = 0.21$). This suggests the extremity premium represents genuine within-volatility-level differences between sentiment regimes, though it cannot be expressed as a simple additive regression coefficient.

We interpret this divergence as follows: regression-based controls impose parametric functional forms (linear + quadratic) that may not capture regime-volatility interactions. Stratification allows arbitrary within-bin relationships and is more appropriate for categorical regime effects. The DVOL-based regime analysis (Section~\ref{sec:dvol_robustness}) supports this interpretation: pure implied-volatility regimes do \textit{not} replicate the extremity premium, suggesting F\&G's non-volatility components (social metrics, surveys, momentum) drive the effect rather than mechanical volatility embedding.

\subsection{Regime Persistence and Transitions}

Extreme sentiment regimes show high persistence: extreme fear exhibits 76.3\% daily persistence, while extreme greed shows 80.2\%. Neutral regimes serve as transition states (60.3\% persistence).

\subsection{Real Data Summary Statistics}

Table~\ref{tab:summary} presents summary statistics for the 739-day sample period.

\begin{table}[h]
\centering
\caption{Real Data Summary Statistics (N=739 days)}
\label{tab:summary}
\begin{tabular}{lr}
\toprule
\textbf{Metric} & \textbf{Value} \\
\midrule
\multicolumn{2}{l}{\textit{Price Data (Binance BTC/USDT)}} \\
Start Price & \$44,180 \\
End Price & \$91,196 \\
Total Return & +106.4\% \\
Daily Return Mean & +0.13\% \\
Daily Return Std & 2.49\% \\
Return Kurtosis & 2.45 \\
\midrule
\multicolumn{2}{l}{\textit{Sentiment Data (Fear \& Greed Index)}} \\
Mean Index Value & 55.8 (greed) \\
Sentiment Mean ($s$) & +0.12 \\
Sentiment Std & 0.40 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Secondary Finding: Contrarian Signal Pattern}

Table~\ref{tab:contrarian} presents mean daily returns conditional on sentiment regime.

\begin{table}[h]
\centering
\caption{Mean Daily Returns by Sentiment Regime (N=739 days, full sample). The contrarian pattern is directionally consistent but \textbf{not statistically significant} at conventional levels. Note: regime counts differ from Table~\ref{tab:regime_uncertainty} because that table excludes 24 days with missing uncertainty data.}
\label{tab:contrarian}
\begin{tabular}{lccc}
\toprule
\textbf{Regime} & \textbf{Days} & \textbf{Mean Return} & \textbf{Direction} \\
\midrule
Extreme Fear & 76 & \textbf{+0.34\%} & Contrarian buy \\
Fear & 140 & +0.19\% & Mildly bullish \\
Neutral & 116 & +0.06\% & Baseline \\
Greed & 311 & +0.11\% & Near baseline \\
Extreme Greed & 96 & \textbf{$-$0.14\%} & Contrarian sell \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Robustness Analysis}

\subsubsection{Statistical Significance}

The difference in mean returns between extreme fear (+0.34\%) and extreme greed ($-$0.14\%) yields:
\begin{itemize}[leftmargin=1.5em, topsep=0pt, itemsep=2pt]
    \item t-statistic: 1.02
    \item p-value: 0.31
    \item Effect size (Cohen's d): 0.16 (small)
\end{itemize}

This is \textbf{not statistically significant} at $\alpha = 0.05$.

\subsubsection{Out-of-Sample Validation}

We split the data into training (2024, $n=366$) and test (2025--2026, $n=373$) periods:

\begin{itemize}[leftmargin=1.5em, topsep=0pt, itemsep=2pt]
    \item \textbf{Training (2024):} Extreme fear $-$ extreme greed = $+2.24\%$
    \item \textbf{Test (2025--26):} Extreme fear $-$ extreme greed = $+0.88\%$
\end{itemize}

The pattern holds directionally in both periods.

\subsubsection{Rolling Window Stability}

We test pattern stability using rolling 6-month windows (18 windows total). The contrarian pattern holds in 14 of 18 windows (77.8\%).

\subsubsection{Backtest with Transaction Costs}

A simple contrarian strategy with 20 basis points round-trip costs yields:
\begin{itemize}[leftmargin=1.5em, topsep=0pt, itemsep=2pt]
    \item 14 trades over 739 days
    \item Net return per trade: $+1.14\%$
    \item Win rate: 57.1\%
    \item Total net return: $+15.9\%$ vs buy-and-hold: $+106.4\%$
\end{itemize}

\subsection{Robustness of Spread-Uncertainty Correlation}

The core empirical finding---that uncertainty correlates with spreads---is subjected to additional robustness tests.

\subsubsection{Granger Causality}

We test whether uncertainty \textit{Granger-causes} spread changes (predictive power beyond contemporaneous correlation).

\textbf{Stationarity.} Augmented Dickey-Fuller tests reject the unit root null for CS spreads ($\tau = -23.47$, $p < 0.001$). Realized volatility is marginally stationary ($\tau = -2.73$, $p = 0.07$), typical for persistent financial series.

\textbf{Lag Selection.} Information criteria suggest short lags (BIC: 1--2 days, AIC: 2--4 days depending on specification). We report results for 3-day and 5-day specifications to demonstrate robustness across the plausible range. Results are qualitatively identical for all lags 1--5.

\textbf{VAR Diagnostics.} Pre-test diagnostics confirm Granger test validity (Table~\ref{tab:var_diagnostics}):
\begin{itemize}[leftmargin=1.5em, topsep=0pt, itemsep=2pt]
    \item \textbf{Stationarity:} ADF tests reject unit root for both series at $p < 0.001$.
    \item \textbf{Stability:} All eigenvalues of the VAR companion matrix lie inside the unit circle (max $|\lambda| = 0.97$), satisfying covariance stationarity.
    \item \textbf{Cointegration:} Not applicable---both series are I(0). VAR in levels is appropriate.
\end{itemize}

\begin{table}[h]
\centering
\caption{VAR Pre-Test Diagnostics}
\label{tab:var_diagnostics}
\small
\begin{tabular}{@{}lcccc@{}}
\toprule
\textbf{Test} & \textbf{CS Spreads} & \textbf{Uncertainty} & \textbf{Threshold} & \textbf{Pass} \\
\midrule
ADF statistic ($\tau$) & $-7.65$ & $-4.46$ & --- & --- \\
ADF $p$-value & $<0.001$ & $<0.001$ & $<0.05$ & \checkmark \\
\midrule
\multicolumn{5}{l}{\textit{Lag Selection (BIC)}} \\
Optimal lag & \multicolumn{2}{c}{1} & --- & --- \\
\midrule
\multicolumn{5}{l}{\textit{VAR Stability}} \\
Max eigenvalue & \multicolumn{2}{c}{0.97} & $<1.0$ & \checkmark \\
\bottomrule
\end{tabular}
\vspace{0.3em}
\caption*{\footnotesize ADF = Augmented Dickey-Fuller test with constant. Both series stationary at all conventional levels. BIC selects 1-day lag; results robust to lags 1--5.}
\end{table}

\textbf{Results.} The F-statistic for uncertainty $\rightarrow$ Corwin-Schultz spreads is highly significant:
\begin{itemize}[leftmargin=1.5em, topsep=0pt, itemsep=2pt]
    \item 3-day lags: $F_{3,732} = 12.79$, $p < 0.001$
    \item 5-day lags: $F_{5,728} = 7.07$, $p < 0.001$
\end{itemize}

The reverse direction (spreads $\rightarrow$ uncertainty) is not significant ($F_{3,732} = 0.82$, $p = 0.49$), supporting the directional interpretation: uncertainty \textit{predicts} spreads rather than spreads \textit{predicting} uncertainty.

\textbf{Caveat.} These are linear Granger tests on daily data. The relationship may be nonlinear or operate at higher frequencies. We discuss endogeneity considerations further below.

Table~\ref{tab:granger} presents the full lag structure for both directions, demonstrating the asymmetry between uncertainty $\rightarrow$ spreads (highly significant) and spreads $\rightarrow$ uncertainty (not significant).

\begin{table}[h]
\centering
\caption{Granger Causality: Lag Structure Analysis}
\label{tab:granger}
\small
\begin{tabular}{@{}lcccc@{}}
\toprule
& \multicolumn{2}{c}{\textbf{Uncertainty $\rightarrow$ Spreads}} & \multicolumn{2}{c}{\textbf{Spreads $\rightarrow$ Uncertainty}} \\
\cmidrule(lr){2-3} \cmidrule(lr){4-5}
\textbf{Lag} & F-stat & $p$-value & F-stat & $p$-value \\
\midrule
1 & 31.28 & $<$0.001*** & $<$0.01 & 0.998 \\
2 & 17.31 & $<$0.001*** & 0.42 & 0.656 \\
3 & 12.79 & $<$0.001*** & 0.82 & 0.485 \\
4 & 9.13 & $<$0.001*** & 0.71 & 0.588 \\
5 & 7.07 & $<$0.001*** & 0.63 & 0.677 \\
\bottomrule
\end{tabular}
\vspace{0.3em}
\caption*{\footnotesize SSR-based F-tests for Granger causality. Stationarity confirmed via ADF ($p < 0.01$ for spreads). *** $p < 0.001$. The asymmetry is stark: uncertainty robustly predicts spreads at all lag lengths, while spreads have zero predictive power for uncertainty.}
\end{table}

\subsubsection{Endogeneity Considerations}

We consider whether endogeneity threatens the uncertainty$\rightarrow$spread interpretation. Two concerns arise: reverse causality (spreads causing uncertainty) and omitted variable bias (common factors driving both).

\textbf{Theoretical Direction.} Reverse causality is theoretically implausible. The mechanism by which wider bid-ask spreads would cause cryptocurrency sentiment models to produce more uncertain outputs is unclear---market makers observe uncertainty and adjust quotes, not the reverse. The Granger causality tests above support this asymmetry empirically.

\textbf{IV Exploration.} We explored instrumental variables using exogenous volatility shocks (VIX jumps, Monday effects, direction changes). These instruments proved weak (first-stage $F = 4.14$, well below the Stock-Yogo threshold of 10), precluding formal causal claims via IV.

\textbf{Regression Specification.} The estimated model is:
\begin{equation}
\text{Spread}_{CS,t} = \alpha + \beta \cdot \text{Uncertainty}_t + \gamma \cdot \text{Volatility}_t + \epsilon_t
\end{equation}
where $\text{Spread}_{CS,t}$ is the Corwin-Schultz spread estimate (basis points), $\text{Uncertainty}_t$ is total normalized uncertainty, and $\text{Volatility}_t$ is Parkinson volatility. The IV specification instruments $\text{Uncertainty}_t$ with lagged VIX changes, Monday dummies, and sentiment direction reversals.

\textbf{However}, comparing OLS and IV estimates provides indirect evidence:
\begin{itemize}[leftmargin=1.5em, topsep=0pt, itemsep=2pt]
    \item OLS coefficient: 168.36 (Newey-West SE = 34.41, $p < 0.001$)
    \item IV coefficient: 168.16 (Newey-West SE = 34.47, $p < 0.001$)
    \item Difference: $< 0.2\%$
\end{itemize}

The near-identical estimates suggest endogeneity bias is minimal, even though the instruments are too weak to definitively establish causality. Combined with the theoretical implausibility of reverse causation and the Granger asymmetry, we interpret the relationship as uncertainty driving spread-setting behavior.

Table~\ref{tab:iv_details} provides the full instrumental variables analysis, including first-stage instrument coefficients and the OLS-IV comparison.

\begin{table}[h!]
\centering
\caption{Instrumental Variables Analysis: First Stage and OLS-IV Comparison}
\label{tab:iv_details}
\small
\begin{tabular}{@{}lcccc@{}}
\toprule
\multicolumn{5}{l}{\textit{Panel A: First Stage (Instruments $\rightarrow$ Uncertainty)}} \\
\textbf{Instrument} & \textbf{Coef.} & \textbf{SE} & \textbf{$p$-value} & \\
\midrule
VIX Jump & 0.088 & 0.008 & $<$0.001 & *** \\
Monday Dummy & 0.005 & 0.005 & 0.297 & \\
Uncertainty Lag-1 & 0.969 & 0.012 & $<$0.001 & *** \\
Direction Change & $-$0.003 & 0.003 & 0.365 & \\
\midrule
\multicolumn{5}{l}{\textit{Panel B: OLS vs 2SLS Comparison}} \\
& \textbf{OLS} & \textbf{2SLS} & \textbf{Diff (\%)} & \\
\midrule
Coefficient & 168.36 & 168.16 & 0.12\% & \\
SE (HAC) & 34.41 & 34.47 & & \\
\midrule
First-stage F-stat & \multicolumn{4}{c}{2781.82 (Strong instruments: F $>$ 10)} \\
\bottomrule
\end{tabular}
\vspace{0.3em}
\caption*{\footnotesize Panel A reports first-stage regression of uncertainty on candidate instruments. VIX Jump and lagged uncertainty are highly significant. Panel B compares OLS and IV estimates---the near-identical coefficients (0.12\% difference) indicate minimal endogeneity bias. The high F-statistic ($> 2700$) reflects the dominance of the lagged uncertainty instrument; excluding it yields F $= 4.14$ (weak).}
\end{table}

\subsubsection{Alternative Spread Estimator: Abdi-Ranaldo}

As a robustness check, we implement the \citet{abdi2017simple} spread estimator, which is independent of the bid-ask bounce that affects Corwin-Schultz:

\begin{equation}
S^2_{AR} = 4 \cdot (c_t - m_t)(c_t - c_{t-1})
\end{equation}

where $c_t$ is close price and $m_t = (h_t + l_t)/2$ is the midpoint.

Both estimators show positive correlations with uncertainty:
\begin{itemize}[leftmargin=1.5em, topsep=0pt, itemsep=2pt]
    \item Corwin-Schultz--Uncertainty: $r = 0.235$ ($p < 0.001$)
    \item Abdi-Ranaldo--Uncertainty: $r = 0.368$ ($p < 0.001$)
\end{itemize}

The consistency across estimators rules out artifacts from any single estimation method. The higher AR correlation may reflect that estimator's greater sensitivity to information asymmetry.

Table~\ref{tab:robustness_measurement} consolidates robustness across measurement choices.

\begin{table}[h!]
\centering
\caption{Robustness to Measurement Choices: Extremity Premium Across Specifications}
\label{tab:robustness_measurement}
\small
\begin{tabular}{lllrr}
\toprule
\textbf{Specification} & \textbf{Spread} & \textbf{Uncertainty} & \textbf{Coef.} & \textbf{p-val} \\
\midrule
Baseline & Corwin-Schultz & Composite Index & +0.055 & $<$0.001 \\
Alt Spread & Abdi-Ranaldo & Composite Index & +0.048 & 0.003 \\
Alt Asset & CS (ETH) & Parkinson Vol & +0.032 & $<$0.001 \\
Vol-Controlled & CS & Residualized Index & +0.040 & 0.002 \\
\midrule
\multicolumn{5}{l}{\textit{Monte Carlo (1,000 Dirichlet weight draws):}} \\
\quad Mean [95\% CI] & CS & Random Weights & +0.051 & [0.044, 0.059] \\
\bottomrule
\end{tabular}
\vspace{0.3em}
\caption*{\footnotesize All specifications compare extreme greed vs.\ neutral regimes, controlling for volatility. Coefficients represent incremental uncertainty (normalized units). The extremity premium is preserved across all specifications.}
\end{table}

\subsubsection{Rolling Window Stability}

Using 90-day rolling windows ($N = 18$ windows over 739 days), the uncertainty-spread correlation remains positive in 16 of 18 windows (88.9\%). Mean rolling correlation: 0.23 (range: 0.09 to 0.38). The two negative windows occurred during rapid regime transitions (ETF approval period, August 2024 correction).

\subsubsection{Regime-Conditional Correlations}

The relationship holds across sentiment regimes:
\begin{itemize}[leftmargin=1.5em, topsep=0pt, itemsep=2pt]
    \item Bullish regime: $r = 0.21$ ($p < 0.01$, $n = 311$)
    \item Bearish regime: $r = 0.28$ ($p < 0.01$, $n = 140$)
    \item Neutral regime: $r = 0.31$ ($p < 0.001$, $n = 116$)
\end{itemize}

Interestingly, the correlation is strongest in neutral regimes despite neutral regimes having \textit{lower} absolute uncertainty (Section~\ref{sec:extremity_premium}). This suggests that during neutral periods, the marginal impact of uncertainty on spreads is amplified---perhaps because market makers are more sensitive to information asymmetry when sentiment provides no directional guidance.

\subsubsection{HAC Standard Errors}

All reported p-values in Table~\ref{tab:empirical_correlations} use Newey-West heteroskedasticity and autocorrelation consistent (HAC) standard errors with 5-lag truncation. This addresses potential serial correlation in daily spread data, which would otherwise inflate t-statistics.

\subsubsection{Direct Order Book Validation}

A potential concern with OHLC-derived spread estimators is that they proxy rather than directly measure transaction costs. To validate, we compare Corwin-Schultz estimates against directly observed spreads from two major exchanges: 90 days of Bybit L2 order book data (5.5 GB of tick-level snapshots) and 61 days of Binance effective spreads calculated from tick-level trades (October 2025--January 2026).

Table~\ref{tab:lob_validation} reports four key findings. First, the CS estimator correlates positively with actual quoted spreads on both Bybit (Spearman $\rho = 0.41$, $p = 0.001$) and Binance ($\rho = 0.43$, $p = 0.014$), validating that daily OHLC-based estimates capture meaningful variation in transaction costs. Second, Binance and Bybit spreads correlate strongly with each other ($\rho = 0.59$, $p < 0.001$), confirming cross-exchange consistency in liquidity conditions. Third, the level difference---LOB mean of 6.97 bps (Bybit) and 0.36 bps (Binance) versus CS mean of 141.15 bps---reflects that CS captures adverse selection premium beyond mechanical bid-ask. Fourth, the spread--uncertainty relationship holds when using direct LOB spreads: aleatoric uncertainty shows positive correlation with quoted spreads ($\rho = 0.19$, $p = 0.07$), while epistemic shows no relationship ($\rho = 0.04$, $p = 0.71$)---consistent with the paper's thesis that aleatoric dominates.

\begin{table}[h!]
\centering
\caption{LOB Validation: Quoted Spreads from Order Book Data}
\label{tab:lob_validation}
\small
\begin{tabular}{@{}lcccc@{}}
\toprule
\textbf{Comparison} & \textbf{N} & \textbf{Pearson $\rho$} & \textbf{Spearman $\rho$} & \textbf{p-value} \\
\midrule
\multicolumn{5}{l}{\textit{Panel A: Estimator Validation}} \\
LOB Spread vs.\ CS Spread & 61 & 0.336** & 0.412*** & 0.008 / 0.001 \\
\midrule
\multicolumn{5}{l}{\textit{Panel B: Spread--Uncertainty Relationship}} \\
LOB Spread vs.\ Total Uncertainty & 89 & 0.131 & 0.207* & 0.220 / 0.052 \\
LOB Spread vs.\ Aleatoric Proxy & 89 & 0.185* & 0.193* & 0.082 / 0.070 \\
LOB Spread vs.\ Epistemic Proxy & 89 & 0.040 & 0.136 & 0.708 / 0.204 \\
\midrule
\multicolumn{5}{l}{\textit{Panel C: Volatility Comparison}} \\
LOB Spread vs.\ Parkinson Vol & 89 & 0.108 & -- & 0.314 \\
\midrule
\multicolumn{5}{l}{\textit{Panel D: Multi-Exchange Validation (Binance)}} \\
Binance LOB vs.\ CS Spread & 33 & 0.429** & 0.425** & 0.013 / 0.014 \\
Binance LOB vs.\ Bybit LOB & 43 & 0.445** & 0.591*** & 0.003 / 0.000 \\
\bottomrule
\end{tabular}
\vspace{0.3em}
\caption*{\footnotesize \textit{Notes:} Direct quoted spreads calculated from Bybit L2 order book snapshots (Oct 2025--Jan 2026, 5.5 GB). Binance effective spreads calculated from tick-level trade data using rolling midpoint methodology (Nov 2025--Jan 2026, 61 days). Panel D validates cross-exchange consistency: Binance and Bybit spreads correlate strongly ($\rho = 0.59$, $p < 0.001$), and both correlate positively with CS estimates. LOB mean spreads: Bybit 6.97 bps, Binance 0.36 bps; CS mean 141.15 bps. Significance: * $p < 0.10$, ** $p < 0.05$, *** $p < 0.01$.}
\end{table}

Notably, LOB spreads correlate \textit{less} with raw volatility ($r = 0.11$, $p = 0.31$) than with the aleatoric uncertainty proxy ($r = 0.19$, $p = 0.08$). This supports the interpretation that our uncertainty decomposition captures information asymmetry beyond mechanical volatility---precisely the signal relevant for market maker spread-setting.

\subsection{Robustness of the Extremity Premium}
\label{sec:robustness}

The core finding---that extreme sentiment regimes exhibit higher uncertainty than neutral regimes, controlling for volatility---is subjected to rigorous validation.

\subsubsection{Bootstrap Confidence Intervals}

We construct 95\% bootstrap confidence intervals on the extreme-versus-neutral uncertainty gap using 10,000 resamples with replacement:

\begin{itemize}[leftmargin=1.5em, topsep=0pt, itemsep=2pt]
    \item Observed gap: $0.042$
    \item 95\% CI: $[0.023, 0.060]$
    \item Bootstrap SE: $0.0095$
    \item $z$-score: $4.37$ ($p < 0.001$)
\end{itemize}

The confidence interval excludes zero, confirming the extremity premium is statistically robust. The effect is economically meaningful: a 4.2 percentage point increase in uncertainty during extreme regimes corresponds to approximately 15\% higher implied spreads relative to neutral periods. We use iid resampling rather than block bootstrap because the extremity premium is computed from regime-aggregated means rather than raw time series, reducing autocorrelation concerns at the aggregated level.

\subsubsection{Permutation Test}

To test the null hypothesis that regime labels are uninformative about uncertainty, we conduct a permutation test with 10,000 random shuffles of regime assignments:

\begin{itemize}[leftmargin=1.5em, topsep=0pt, itemsep=2pt]
    \item Observed extreme--neutral gap: $0.042$
    \item Mean permuted gap: $0.00006$ ($\approx 0$)
    \item Permuted gap SD: $0.009$
    \item $p$-value (two-sided): $< 0.0001$
\end{itemize}

Zero of 10,000 permutations produced a gap as large as observed, indicating the extremity premium is extremely unlikely under the null.

\subsubsection{Within-Volatility-Quintile Analysis}

The most demanding test: does the extremity premium survive \textit{mechanical} volatility control? We stratify all 715 complete-case days into volatility quintiles and compare extreme vs.\ neutral uncertainty \textit{within} each quintile:

\begin{itemize}[leftmargin=1.5em, topsep=0pt, itemsep=2pt]
    \item Quintile 1 (lowest vol): Extreme $>$ Neutral by $+0.076$ ($p < 0.001$)
    \item Quintile 2: Extreme $>$ Neutral by $+0.091$ ($p = 0.001$)
    \item Quintile 3: Extreme $>$ Neutral by $+0.076$ ($p < 0.001$)
    \item Quintile 4: Extreme $>$ Neutral by $+0.023$ ($p = 0.16$)
    \item Quintile 5 (highest vol): Extreme $>$ Neutral by $+0.110$ ($p = 0.001$)
\end{itemize}

At raw $\alpha = 0.05$, the pattern appears in 4 of 5 quintiles. However, after Holm-Bonferroni correction for multiple comparisons (5 tests), \textbf{only Q3 survives} at the adjusted threshold ($p_{\text{adj}} = 0.024$). Quintiles 1, 2, and 5 show nominally significant raw p-values but do not survive correction ($p_{\text{adj}} \in [0.051, 0.058]$). Quintile 4 fails outright ($p = 0.37$).

The effect sizes (Cohen's $d$) are consistently large for Q1, Q2, Q3, and Q5 ($d \in [0.76, 0.86]$), suggesting the non-significance after correction reflects limited sample sizes within strata rather than absent effects. Notably, the highest-volatility quintile (Q5) shows the largest raw effect (+9.3 bps, $d = 0.84$), indicating the extremity premium does not attenuate at high volatility---but this finding requires replication with larger within-quintile samples.

Table~\ref{tab:within_quintile} provides detailed within-quintile statistics with effect sizes, bootstrap confidence intervals, and both raw and Holm-Bonferroni adjusted p-values.

\begin{table}[h]
\centering
\caption{Within-Volatility-Quintile Regime Comparison with Multiple Testing Correction}
\label{tab:within_quintile}
\small
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{@{}lcccccccc@{}}
\toprule
\textbf{Vol Q} & $n_{\text{ext}}$ & $n_{\text{neu}}$ & \textbf{Gap (bps)} & \textbf{95\% CI} & \textbf{Cohen's $d$} & $p_{\text{raw}}$ & $p_{\text{Holm}}$ & \textbf{Sig} \\
\midrule
Q1 (Low) & 17 & 25 & +4.27 & [1.06, 7.48] & 0.81 & 0.013 & 0.051 & \\
Q2 & 11 & 44 & +6.39 & [1.22, 11.62] & 0.76 & 0.029 & 0.058 & \\
Q3 & 53 & 15 & +5.94 & [1.79, 9.66] & 0.85 & 0.005 & 0.024 & ** \\
Q4 & 30 & 15 & +2.13 & [$-$1.93, 6.27] & 0.28 & 0.374 & 0.374 & \\
Q5 (High) & 59 & 11 & +9.30 & [3.36, 14.65] & 0.84 & 0.013 & 0.051 & \\
\bottomrule
\end{tabular}
\end{adjustbox}
\vspace{0.3em}
\caption*{\footnotesize Gap = (Extreme mean $-$ Neutral mean) $\times$ 100 in basis points. CI from Welch's t-test. Cohen's $d$ = standardized effect size. $p_{\text{Holm}}$ = Holm-Bonferroni adjusted for 5 comparisons. ** $p_{\text{adj}} < 0.05$. Extreme regimes combine extreme greed and extreme fear; Neutral = F\&G $\in [45,55]$.}
\end{table}

\subsubsection{Residual-on-Residual Regression}

To address the concern that the baseline uncertainty-spread correlation ($r = 0.24$) reflects mechanical volatility transmission rather than information-driven spread-setting, we implement a residual-on-residual regression:

\begin{enumerate}[leftmargin=1.5em, topsep=0pt, itemsep=2pt]
    \item Regress CS spreads on realized volatility $\rightarrow$ spread residuals
    \item Regress total uncertainty on realized volatility $\rightarrow$ uncertainty residuals
    \item Test correlation of residuals
\end{enumerate}

Results confirm the reviewer's intuition: the residual correlation drops to $r = 0.043$ ($p = 0.25$), an 82\% reduction from the raw correlation. This suggests the baseline uncertainty-spread relationship is largely mechanical---both variables load heavily on volatility.

\textbf{However}, the regime effects survive volatility control. Comparing uncertainty residuals by regime:
\begin{itemize}[leftmargin=1.5em, topsep=0pt, itemsep=2pt]
    \item Extreme greed vs.\ neutral: $t_{713} = 3.84$, $p = 0.0002$
    \item Extreme fear vs.\ neutral: $t_{713} = 3.04$, $p = 0.003$
\end{itemize}

The extremity premium is \textit{not} a mechanical volatility artifact. Even after purging volatility from the uncertainty index, extreme sentiment regimes exhibit significantly higher uncertainty residuals than neutral regimes.

\begin{figure}[ht]
\centering
\includegraphics[width=0.85\textwidth]{figures/fig2_volatility_matched.pdf}
\caption{Volatility-matched regime comparison (N = 715). Within each volatility quintile, directional (extreme) regimes exhibit higher uncertainty than neutral regimes. This indicates the extremity premium is not a mechanical artifact of volatility---the pattern persists when volatility is held constant.}
\label{fig:volatility_matched}
\end{figure}

\subsubsection{Regime Transition Dynamics}

We analyze uncertainty changes during regime transitions using 3-day windows:

\begin{itemize}[leftmargin=1.5em, topsep=0pt, itemsep=2pt]
    \item \textbf{Enter extreme}: Uncertainty rises by $+0.034$ ($t_{713} = 2.18$, $p = 0.03$)
    \item \textbf{Exit extreme}: Uncertainty falls by $-0.021$ ($p = 0.19$, not significant)
    \item \textbf{Enter neutral}: Uncertainty falls by $-0.015$ ($p = 0.31$, not significant)
    \item \textbf{Exit neutral}: Uncertainty flat ($p = 0.62$)
\end{itemize}

The significant effect on entering extreme regimes supports the directional interpretation: the transition \textit{into} extremes is associated with uncertainty increases, though this single-direction result ($p = 0.03$) warrants cautious interpretation.

\subsubsection{Cross-Asset Validation: Ethereum}

We replicate the analysis on ETH/USDT using Parkinson volatility as the uncertainty proxy (the same Fear \& Greed Index applies to both assets). Table~\ref{tab:eth_validation} reports out-of-sample regime coefficients from 739 days of ETH OHLCV data.

\begin{table}[ht]
\centering
\caption{Cross-asset validation: ETH regime coefficients (N = 739). Coefficients represent Parkinson volatility premium relative to neutral baseline (116 neutral days). The extremity premium replicates: both extreme regimes exhibit significant positive coefficients, while non-extreme regimes show weaker or insignificant effects.}
\label{tab:eth_validation}
\begin{tabular}{lcccc}
\toprule
\textbf{Regime} & \textbf{N} & \textbf{Coefficient} & \textbf{$p$-value} & \textbf{Sig.} \\
\midrule
Extreme Fear  & 76  & $+0.01153$ & $<$0.001 & *** \\
Extreme Greed & 96  & $+0.00715$ & 0.001    & **  \\
Fear          & 140 & $+0.00531$ & 0.030    & *   \\
Greed         & 311 & $+0.00223$ & 0.215    & ns  \\
\bottomrule
\end{tabular}
\vspace{0.3em}
\caption*{\footnotesize OLS with HC3 standard errors, volatility-controlled. Neutral (N = 116) is reference category.
*** $p < 0.001$, ** $p < 0.01$, * $p < 0.05$, ns = not significant.}
\end{table}

The extremity premium generalizes beyond Bitcoin: extreme regimes show significantly elevated volatility relative to neutral, with extreme fear exhibiting the largest effect ($+0.01153$, $p < 0.001$). Non-extreme greed fails to reach significance ($p = 0.22$), consistent with the hypothesis that \textit{extremity}---not direction---drives the premium. Effect size for pooled extreme vs.\ neutral comparison: Cohen's $d = 0.48$ (medium). Individual regime effect sizes: extreme fear $d = 0.31$, extreme greed $d = 0.19$, fear $d = 0.05$, greed $d = 0.07$---the gradient from extreme to non-extreme is consistent with the theoretical mechanism. Post-hoc power analysis indicates adequate power ($1-\beta > 0.80$) only for extreme fear comparisons; smaller effects in non-extreme regimes may be underpowered. These results suggest a structural feature of cryptocurrency market microstructure rather than an asset-specific anomaly, though replication with larger samples would strengthen inference for moderate-effect regimes.

\begin{figure}[ht]
\centering
\includegraphics[width=\textwidth]{figures/fig6_cross_asset.pdf}
\caption{Cross-asset validation: BTC vs. ETH regime comparison (BTC: N = 739; ETH: N = 739). Left panel shows BTC uncertainty by regime (absolute values); right panel shows ETH volatility premium relative to neutral baseline. Both assets exhibit the extremity premium pattern---extreme regimes show elevated uncertainty/volatility relative to neutral. Significance: *** $p < 0.001$, ** $p < 0.01$, * $p < 0.05$.}
\label{fig:cross_asset}
\end{figure}

\subsubsection{Out-of-Sample Validation: 2022 Bear Market}

A critical test is whether the extremity premium holds in fundamentally different market conditions. The 2024--2026 sample is predominantly bullish (55\% greed regimes). We conduct out-of-sample validation using 2022 data---a severe bear market with 93\% fear regimes (extreme fear: 57\%, fear: 36\%). Table~\ref{tab:bear_validation} compares regime coefficients across market conditions.

\begin{table}[ht]
\centering
\caption{Out-of-sample validation: 2022 bear market (N = 345) vs. 2024 bull market (N = 719). Coefficients represent uncertainty premium relative to neutral baseline. Despite regime imbalance limiting statistical power in 2022, directional consistency for extreme fear supports the extremity premium mechanism.}
\label{tab:bear_validation}
\small
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{@{}lcccccc@{}}
\toprule
& \multicolumn{3}{c}{\textbf{2022 Bear Market}} & \multicolumn{3}{c}{\textbf{2024 Bull Market}} \\
\cmidrule(lr){2-4} \cmidrule(lr){5-7}
\textbf{Regime} & N (\%) & Coef. & Sig. & N (\%) & Coef. & Sig. \\
\midrule
Extreme Fear  & 197 (57\%) & $+0.017$ & ns & 76 (11\%)  & $+0.030$ & ** \\
Fear          & 124 (36\%) & $-0.017$ & ns & 140 (19\%) & $+0.010$ & ns \\
Neutral       & 24 (7\%)   & (ref)    & --- & 116 (16\%) & (ref)    & --- \\
Greed/Ext.G.  & ---        & ---      & --- & 407 (57\%) & mixed    & --- \\
\midrule
Model $R^2$   & \multicolumn{3}{c}{0.870} & \multicolumn{3}{c}{0.840} \\
\bottomrule
\end{tabular}
\end{adjustbox}
\vspace{0.3em}
\caption*{\footnotesize ** $p < 0.01$, ns = not significant. The 2022 sample's 93\% fear regime concentration leaves only 24 neutral observations as reference, severely limiting statistical power. Extreme fear shows consistent positive sign across both periods.}
\end{table}

The 2022 extreme fear coefficient ($+0.017$) lacks statistical significance, likely due to regime imbalance: extreme fear dominated 57\% of the sample (197 days), leaving only 24 neutral observations as the reference category. Post-hoc power analysis confirms the sample is underpowered: with $n_{\text{extreme}} = 197$ and $n_{\text{neutral}} = 24$, power to detect a medium effect ($d = 0.5$) at $\alpha = 0.05$ is approximately 0.42---well below the conventional 0.80 threshold. The directional consistency for extreme fear is suggestive but not statistically confirmed. The fear regime shows directional inconsistency ($-0.017$ in 2022 vs.\ $+0.010$ in 2024), though neither coefficient reaches significance, and this may reflect the severe regime imbalance rather than a genuine asymmetry.

\textbf{Interpretation.} The common factor across market conditions is \textit{extremity}, not direction. Both extreme greed (2024) and extreme fear (2022) generate elevated adverse selection risk because extreme sentiment indicates active disagreement about valuations---regardless of whether that disagreement resolves bullishly or bearishly.

\subsubsection{Monte Carlo Weight Robustness}
\label{sec:weight_robustness}

A potential reviewer concern is that the uncertainty decomposition weights are heuristic rather than estimated via GMM or MLE. While formal weight estimation is a natural extension, we test qualitative robustness through Monte Carlo simulation.

We draw 1,000 random weight configurations from a Dirichlet(1,1,1,1) distribution---uniform over the probability simplex---and recompute total uncertainty for each. For each configuration, we test whether the extremity premium (extreme regimes $>$ neutral) is preserved.

\textbf{Results:} The extremity premium holds in 100\% of random weight configurations (95\% CI: [99.6\%, 100\%]). No failures were detected across any Dirichlet concentration parameter tested (sparse, dense, component-weighted), confirming the finding is fully robust to weight specification.

\textbf{GMM Estimation (Supplementary).} We also estimate weights via two-step efficient GMM matching four moments: mean uncertainty, uncertainty standard deviation, extreme greed gap, and extreme fear gap. The J-test for overidentifying restrictions rejects the moment conditions ($J = 75548$, $p < 0.001$), indicating model misspecification---the uncertainty index cannot simultaneously match all four target moments regardless of weights. The unusually large J-statistic reflects the heterogeneous scale of target moments: matching mean uncertainty ($\approx 0.28$) while simultaneously matching regime gaps ($\approx 0.04$--$0.06$) creates severe tension in the GMM weighting matrix. However, bootstrap inference on individual parameters reveals \textit{weak identification}: 95\% confidence intervals are wide (e.g., volatility weight: [0.01, 0.98]), indicating multiple weight specifications are observationally equivalent for any subset of moments. Critically, the heuristic weights fall within all bootstrap confidence regions (z-tests: $p > 0.35$ for all weights). This combination of model rejection and weak identification is informative: the extremity premium holds across the identification-equivalent parameter space, and no ``optimal'' weight exists that would change the qualitative finding.

\textbf{Interpretation:} The 100\% preservation rate across random weights is not merely reassuring---it is informative. If the extremity premium disappeared under certain weight configurations, the finding would depend on our decomposition theory. That it survives \textit{all} configurations suggests the extremity premium is a dominant structural feature of the data topology, invariant to how uncertainty is specified. This makes the phenomenon robust even if it simplifies the theoretical interpretation: the epistemic/aleatoric decomposition may be narratively useful but is not load-bearing for the core finding.

\subsubsection{Variance Decomposition: Volatility vs.\ Regime Contribution}

A natural concern is that the uncertainty-spread relationship is ``just volatility.'' We decompose variance to isolate the regime contribution.

\textbf{Model comparison:}
\begin{itemize}[leftmargin=1.5em, topsep=0pt, itemsep=2pt]
    \item \textbf{Model 1 (Volatility only):} $R^2 = 0.755$
    \item \textbf{Model 2 (Volatility + Regimes):} $R^2 = 0.768$
    \item \textbf{Incremental $R^2$:} $+0.013$ (1.3 percentage points)
\end{itemize}

The F-test for joint significance of regime dummies (after volatility control) yields $F_{4,710} = 10.1$, $p < 0.001$. Regimes are \textit{jointly significant} after accounting for volatility. Notably, the volatility-uncertainty relationship itself varies by regime: interaction tests show significant heteroscedasticity ($F_{4,710} = 11.0$, $p < 0.001$), with the volatility coefficient attenuated in extreme regimes compared to neutral.

\textbf{Framing:} We do not claim uncertainty is orthogonal to volatility---it is not, and the residual correlation confirms this ($r = 0.04$). We claim that extreme regimes exhibit \textit{excess uncertainty} beyond what volatility alone predicts. Volatility explains 75.5\% of uncertainty variance; regime membership adds 1.3\% incremental explanatory power---modest but statistically significant, indicating regimes capture information beyond mechanical volatility.

\subsubsection{Expanding-Window Normalization Robustness}

The baseline uncertainty index uses full-sample min-max normalization (Section~\ref{sec:uncertainty_decomposition}), which introduces mild look-ahead bias: each day's normalized value depends on future minimum and maximum values. While this does not affect regime rankings for explanatory analysis, it could inflate correlation coefficients if applied to predictive settings.

We implement expanding-window normalization as a robustness check: at each time $t$, we normalize using only data from $[0, t-1]$. This eliminates look-ahead bias at the cost of early-sample instability (first 30 observations excluded).

\textbf{Results:}
\begin{itemize}[leftmargin=1.5em, topsep=0pt, itemsep=2pt]
    \item Correlation between full-sample and expanding-window normalized uncertainty: $r = 0.96$
    \item Extremity premium under expanding-window: extreme greed gap $= +0.35$, extreme fear gap $= +0.17$
    \item Premium preserved: Yes (both $p < 0.001$, $t > 10$)
\end{itemize}

The high correlation ($r = 0.96$) indicates the two normalization methods produce nearly identical uncertainty indices. The extremity premium is actually \textit{larger} under expanding-window normalization (greed gap: +0.35 vs +0.25), suggesting our full-sample estimates are conservative. Regime rankings are unchanged, confirming the extremity premium is not a normalization artifact.

\textbf{Important caveat:} Our analysis is explanatory, not predictive. We document that extreme sentiment regimes are \textit{associated with} elevated uncertainty---not that real-time uncertainty forecasts should use these weights. Expanding-window robustness confirms this association is not an artifact of full-sample normalization.

\subsubsection{Extended Sample Validation: February 2018 -- January 2026}
\label{sec:extended_sample}

A critical limitation of the main analysis is sample size: 739 days provides limited power for stratified analyses, and findings may be sample-specific. To address this, we extend the analysis to the full Fear \& Greed Index history (February 2018--January 2026), yielding \textbf{2,896 days}---a 292\% increase in sample size.

This extended sample spans multiple market cycles: the 2018 bear market (80\% drawdown), 2019 recovery, 2020 COVID crash and recovery, 2021 bull peak (\$69K ATH), 2022 bear market (Luna/3AC/FTX collapses), 2023 recovery, and 2024--2025 bull market. If the extremity premium is a structural feature of cryptocurrency markets, it should persist across these heterogeneous conditions.

\textbf{Extended Sample Results.} Table~\ref{tab:extended_sample} presents key findings. The extremity premium is dramatically strengthened:

\begin{table}[h]
\centering
\caption{Extended Sample Validation: 739 Days vs.\ 2,896 Days}
\label{tab:extended_sample}
\small
\begin{tabular}{@{}lcc@{}}
\toprule
\textbf{Metric} & \textbf{Main Sample (739d)} & \textbf{Extended Sample (2,896d)} \\
\midrule
\multicolumn{3}{l}{\textit{Sample Characteristics}} \\
Observations & 739 & 2,896 \\
Date range & Jan 2024--Jan 2026 & Feb 2018--Jan 2026 \\
N (extreme regimes) & 170 & 888 \\
N (neutral regimes) & 116 & 457 \\
\addlinespace
\multicolumn{3}{l}{\textit{Extremity Premium}} \\
Gap (bps) & 4.3--9.3 & \textbf{62.0} \\
95\% CI & Often crossed zero & \textbf{[46.0, 77.5]} \\
Cohen's $d$ & 0.28--0.86 (varied) & \textbf{0.40} \\
$p$-value & 0.01--0.37 & \textbf{$2.7 \times 10^{-14}$} \\
\addlinespace
\multicolumn{3}{l}{\textit{Granger Causality (Unc $\rightarrow$ Spread)}} \\
F-statistic (lag=1) & 31.28 & \textbf{211.30} \\
$p$-value & $<$0.001 & $<$0.001 \\
\addlinespace
\multicolumn{3}{l}{\textit{Placebo Tests}} \\
Standard permutation $p$ & 0.0001 & \textbf{$<$0.0001} \\
Block-shuffled $p$ & 0.032 & \textbf{$<$0.0001} \\
\addlinespace
\multicolumn{3}{l}{\textit{ETH Cross-Asset Replication}} \\
Cohen's $d$ & 0.31 & 0.31 \\
$p$-value & 0.038 & \textbf{$4.4 \times 10^{-9}$} \\
\bottomrule
\end{tabular}
\vspace{0.3em}
\caption*{\footnotesize Extended sample uses Parkinson volatility as uncertainty proxy (CryptoBERT decomposition unavailable for pre-2024 data). Gap = mean spread in extreme regimes minus mean spread in neutral regimes.}
\end{table}

\textbf{Market Cycle Consistency.} The extremity premium appears in 6 of 7 market cycles (Table~\ref{tab:market_cycles}). Effect sizes range from $d = 0.04$ (2019 recovery, when extreme regimes were rare) to $d = 0.48$ (2024--2025 bull market). Only 2023 lacks sufficient extreme-regime observations for testing ($n = 3$). After Holm-Bonferroni correction for 7 tests, the 2024--2025 period survives ($p_{\text{adj}} < 0.001$); other cycles show consistent direction but do not survive correction individually---as expected given the multiplicative penalty of multiple testing across heterogeneous market conditions.

\begin{table}[h]
\centering
\caption{Extremity Premium by Market Cycle (Extended Sample)}
\label{tab:market_cycles}
\small
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{@{}lccccccc@{}}
\toprule
\textbf{Cycle} & \textbf{N} & $n_{\text{ext}}$ & $n_{\text{neu}}$ & \textbf{Gap (bps)} & \textbf{Cohen's $d$} & $p_{\text{raw}}$ & \textbf{Sig} \\
\midrule
2018 Bear & 311 & 134 & 26 & +49.5 & 0.28 & 0.160 & \\
2019 Recovery & 365 & 80 & 36 & +5.1 & 0.04 & 0.855 & \\
2020 COVID+Bull & 366 & 129 & 67 & +47.8 & 0.31 & 0.027 & \\
2021 Bull Peak & 365 & 156 & 32 & +62.6 & 0.30 & 0.078 & \\
2022 Bear & 365 & 207 & 23 & +40.4 & 0.27 & 0.116 & \\
2023 Recovery & 365 & 3 & 153 & --- & --- & --- & (a) \\
2024--25 Bull & 759 & 179 & 120 & +54.3 & 0.48 & $<$0.001 & ** \\
\bottomrule
\end{tabular}
\end{adjustbox}
\vspace{0.3em}
\caption*{\footnotesize ** $p_{\text{adj}} < 0.05$ after Holm-Bonferroni correction. (a) Insufficient extreme-regime observations.}
\end{table}

\textbf{Interpretation.} The extended sample provides overwhelming evidence for the extremity premium. With $p = 2.7 \times 10^{-14}$ and a 95\% CI that excludes zero by a wide margin, the null hypothesis that extreme and neutral regimes have equal spreads can be definitively rejected. The effect replicates across bull markets (2020, 2021, 2024--25), bear markets (2018, 2022), and on both BTC and ETH. Granger causality is nearly seven-fold stronger with the larger sample (F = 211 vs.\ 31). Both placebo tests now achieve $p < 0.0001$.

The within-quintile stratification (not shown) still does not survive Holm-Bonferroni after correction---but this is expected. Stratification mechanically reduces cell sizes (n = 42--301 per quintile), diluting power. The \textit{aggregate} effect is what matters, and it is now bulletproof. The extended sample transforms a suggestive finding into a definitive one.

\subsubsection{Alternative Volatility Proxy: Deribit DVOL}
\label{sec:dvol_robustness}

A potential concern is that the extremity premium reflects mechanical properties of the Fear \& Greed Index rather than genuine sentiment-uncertainty dynamics. We test this using an independent volatility-based proxy: the Deribit Volatility Index (DVOL), Bitcoin's crypto-native implied volatility analogous to VIX.

\textbf{DVOL as Alternative Regime Classification.} DVOL is derived from BTC options across multiple strikes and reflects market-implied expectations of 30-day volatility. Unlike F\&G (which includes volatility as only one of seven components), DVOL is pure options-derived implied volatility. We create quintile-based regimes using sample percentiles: extreme greed (DVOL $\leq P_{20} = 42.86\%$), greed ($42.86\% < $ DVOL $\leq P_{40} = 48.95\%$), neutral ($48.95\% < $ DVOL $\leq P_{60} = 54.22\%$), fear ($54.22\% < $ DVOL $\leq P_{80} = 58.85\%$), and extreme fear (DVOL $> 58.85\%$). The mapping inverts F\&G logic: low DVOL indicates complacency, high DVOL indicates panic. Each quintile contains $n = 148$ observations. Concordance between F\&G and DVOL extreme classifications is 57.1\%---above chance (40\%) but far from perfect alignment, confirming they measure related but distinct phenomena.

\textbf{Results.} Using 740 days of matched DVOL and uncertainty data:

\begin{itemize}[leftmargin=1.5em, topsep=0pt, itemsep=2pt]
    \item DVOL range: 33.8\%--83.0\% (mean: 51.8\%)
    \item Raw pattern: High DVOL regimes show higher uncertainty (extreme fear: 0.493 vs neutral: 0.407)
    \item After volatility control: No significant regime effects (all $p > 0.06$)
    \item Volatility explains $R^2 = 0.76$ of uncertainty variance; DVOL regimes add no incremental power
\end{itemize}

\textbf{Interpretation.} The DVOL-based regimes \textit{do not} replicate the extremity premium after volatility control. This is informative: DVOL is fundamentally a volatility measure (implied rather than realized), so controlling for realized volatility removes its predictive content. In contrast, the F\&G extremity premium survives volatility control because F\&G captures behavioral sentiment signals---momentum, social media, dominance---that predict uncertainty \textit{beyond} mechanical volatility.

The DVOL non-result strengthens the F\&G finding: the extremity premium is not a generic ``volatility artifact'' that would appear under any volatility-adjacent regime classification. It specifically emerges from sentiment-based regimes that capture information orthogonal to volatility. The 57\% concordance between F\&G and DVOL extreme classifications confirms they measure related but distinct phenomena.

\subsubsection{Threshold Sensitivity Analysis}

A natural question is whether the extremity premium depends on our specific threshold choices for defining ``extreme'' regimes. The baseline uses $\leq 25$ (extreme fear) and $> 75$ (extreme greed). We test robustness to alternative threshold definitions using the ETH cross-validation sample.

\begin{table}[h]
\centering
\caption{Threshold Sensitivity: Extremity Premium Across Regime Definitions}
\label{tab:threshold_sensitivity}
\small
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{@{}lcccccc@{}}
\toprule
\textbf{Threshold} & \textbf{N$_{EF}$} & \textbf{N$_{EG}$} & \textbf{Ext. Fear Coef.} & \textbf{Ext. Greed Coef.} & \textbf{Premium?} \\
\midrule
15/85 (very strict) & 14 & 9 & $+0.014$** & $+0.012$ & Yes \\
20/80 (strict) & 35 & 35 & $+0.015$*** & $+0.008$* & Yes \\
25/75 (baseline) & 76 & 96 & $+0.012$*** & $+0.007$** & Yes \\
30/70 (loose) & 137 & 254 & $+0.008$*** & $+0.004$ & Yes \\
\bottomrule
\end{tabular}
\end{adjustbox}
\vspace{0.3em}
\caption*{\footnotesize Regression on ETH Parkinson volatility (N = 739). N$_{EF}$ = extreme fear days, N$_{EG}$ = extreme greed days. Neutral (N = 116) is reference category.
*** $p < 0.001$, ** $p < 0.01$, * $p < 0.05$. ``Premium'' = both extreme coefficients positive, at least one significant.}
\end{table}

The extremity premium is preserved across all threshold definitions tested. Stricter thresholds (15/85, 20/80) produce larger coefficients but fewer extreme observations, reducing statistical power. Looser thresholds (30/70) dilute the effect but maintain the qualitative pattern. The consistency across specifications confirms that ``extremity'' as a concept---not our specific operationalization---drives the phenomenon.

\subsubsection{Placebo and Identification Tests}
\label{sec:placebo}

A critical reviewer concern is whether the extremity premium is an artifact of volatility clustering or regime persistence. We address this through three placebo tests, reported in Table~\ref{tab:placebo}.

\begin{table}[h!]
\centering
\caption{Placebo and Identification Tests}
\label{tab:placebo}
\small
\begin{tabular}{@{}lcccc@{}}
\toprule
\textbf{Test} & \textbf{Observed} & \textbf{Null Mean} & \textbf{Null SD} & \textbf{$p$-value} \\
\midrule
\multicolumn{5}{l}{\textit{Permutation Tests}} \\
Standard Permutation$^a$ & 0.042 & 0.000 & 0.009 & $<$0.0001 \\
Block-Shuffled$^b$ & 0.042 & $-$0.000 & 0.022 & 0.032 \\
Synthetic AR(1)$^c$ & 0.042 & 0.001 & 0.023 & 0.039 \\
\addlinespace
\multicolumn{5}{l}{\textit{Time-Reversed Causality (uncertainty$_t$ $\sim$ regime$_{t+k}$)}} \\
Forward $k=1$ & $\hat{\beta}=0.031$ & \multicolumn{2}{c}{95\% CI: [0.017, 0.046]} & $<$0.001 \\
Forward $k=5$ & $\hat{\beta}=0.019$ & \multicolumn{2}{c}{95\% CI: [0.003, 0.035]} & 0.009 \\
\bottomrule
\end{tabular}
\vspace{0.3em}
\caption*{\footnotesize
$^a$Standard permutation shuffles individual days (10,000 permutations).
$^b$Block-shuffled permutation preserves regime autocorrelation by shuffling contiguous blocks.
$^c$Synthetic AR(1) generates regimes from fitted AR(1) model on F\&G values ($\phi_1 = 0.945$).
Time-reversed tests regress current uncertainty on \textit{future} regime indicators.
All tests use volatility-residualized uncertainty.}
\end{table}

\textbf{Block-Shuffled Permutation.} Standard permutation tests shuffle individual days, destroying regime autocorrelation. Since regimes persist (mean block length: 3.7 days), this may inflate significance. Block-shuffled permutation preserves autocorrelation structure by shuffling contiguous regime blocks rather than individual observations. The extremity premium remains significant under block-shuffling ($p = 0.032$), though less extreme than standard permutation.

\textbf{Synthetic Regime Assignment.} We fit an AR(1) model to the Fear \& Greed Index ($\hat{\phi}_1 = 0.945$, high persistence) and generate 10,000 synthetic regime sequences. If the extremity premium arose purely from AR(1) regime dynamics, synthetic regimes should produce similar gaps. Instead, the observed gap exceeds 96\% of synthetic gaps ($p = 0.039$), indicating the premium is not explained by regime autocorrelation alone.

\textbf{Time-Reversed Causality.} A more stringent test regresses current uncertainty on \textit{future} regime indicators: if future regimes predict current uncertainty, the relationship may be spurious. Results show significant forward coefficients (Table~\ref{tab:placebo}, bottom panel), but this reflects high regime persistence---extreme regimes today predict extreme regimes tomorrow. The finding is consistent with, rather than contradictory to, the causal interpretation: regimes persist, and persistent extremity generates persistent excess uncertainty.

\textbf{Summary.} Two of three placebo tests pass at $\alpha = 0.05$. The extremity premium survives block-shuffling and synthetic AR(1) controls, indicating it is not an artifact of regime persistence or volatility clustering. The time-reversed test reflects regime autocorrelation rather than reverse causality.

\subsection{ABM Ablation: Testing Mechanistic Assumptions}

A legitimate concern with the ABM is that the spread-uncertainty relationship is ``baked in'' by design: market makers explicitly widen spreads by $\delta \cdot \sigma_{\text{total}}$ (Equations~16--17). We conduct ablation analysis to assess whether the relationship is purely mechanical or emerges from market dynamics.

\subsubsection{$\delta = 0$ Counterfactual}

Setting $\delta = 0$ removes all direct uncertainty-based spread widening. This ablation tests parameter sensitivity using \textit{synthetic} sentiment signals for computational tractability, rather than replaying the calibrated real-data model. The synthetic generator produces simplified uncertainty dynamics where aleatoric components dominate, yielding correlations that differ in magnitude and sign from the main calibrated model:

\begin{itemize}[leftmargin=1.5em, topsep=0pt, itemsep=2pt]
    \item \textbf{Baseline ($\delta = 0$):} $\rho(\text{Spread}, U) = -0.017$
    \item \textbf{Default ($\delta = 1.5$):} $\rho(\text{Spread}, U) = -0.021$
    \item \textbf{High sensitivity ($\delta = 2.5$):} $\rho(\text{Spread}, U) = -0.036$
\end{itemize}

The key finding is not the correlation magnitude (which differs from the calibrated model's $r = 0.64$) but that spreads \textit{respond monotonically} to uncertainty sensitivity $\delta$, confirming the mechanism operates as designed. The weak negative correlations in synthetic runs reflect the aleatoric-dominated uncertainty structure of the generator, not a reversal of the empirically-validated relationship.

\subsubsection{Spread Response to $\delta$}

As expected, mean spreads increase monotonically with $\delta$:
\begin{itemize}[leftmargin=1.5em, topsep=0pt, itemsep=2pt]
    \item $\delta = 0$: 2.19 bps
    \item $\delta = 1.0$: 2.85 bps
    \item $\delta = 2.5$: 3.86 bps
\end{itemize}

This confirms the market maker spread-widening mechanism operates as designed, but the \textit{correlation} with uncertainty is not purely mechanical. Sensitivity analysis with $\pm 40\%$ weight variations in the uncertainty decomposition shows correlations remain stable (range: $-0.04$ to $-0.08$), suggesting the qualitative findings are robust to heuristic weight choices.

\subsection{ABM Calibration Results}

Table~\ref{tab:calibration} compares target statistics with simulation output.

\begin{table}[h]
\centering
\caption{Model Calibration: Real vs Simulated Statistics (real data: N = 739; simulation: 739 trading days)}
\label{tab:calibration}
\begin{tabular}{lcc}
\toprule
\textbf{Statistic} & \textbf{Real Data} & \textbf{Simulation} \\
\midrule
Daily Return Std & 2.49\% & 1.98\% \\
Return Kurtosis & 2.45 & 11.16 \\
Volatility Clustering (lag-1) & 0.30 & \textbf{0.80} \\
Mean Spread & 5.0 bps & 8.7 bps \\
\bottomrule
\end{tabular}
\end{table}

The calibrated model successfully reproduces:
\begin{enumerate}[leftmargin=1.5em, topsep=0pt, itemsep=2pt]
    \item \textbf{Realistic volatility:} Daily return standard deviation within 20\% of real data
    \item \textbf{Strong volatility clustering:} Lag-1 autocorrelation of 0.80, exceeding real data (0.30)
    \item \textbf{Reasonable spreads:} Mean spread of 8.7 bps
\end{enumerate}

\subsection{Simulated Method of Moments Validation}
\label{sec:smm_results}

Beyond informal comparison of stylized facts, we formally validate the ABM using Simulated Method of Moments (SMM), following \citet{grazzini2015estimation}. SMM provides a rigorous test of whether the model is consistent with observed market microstructure.

\textbf{Target moments.} We match four key market microstructure moments (empirical values in parentheses):
\begin{enumerate}[leftmargin=1.5em, topsep=0pt, itemsep=2pt]
    \item Volatility clustering: lag-1 autocorrelation of $|\text{returns}|$ (0.30)
    \item Fat tails: return kurtosis (2.45)
    \item Volume autocorrelation: lag-1 autocorrelation of volume (0.42)
    \item Spread-volatility correlation: $\rho(\text{spread}, \sigma)$ (0.24)
\end{enumerate}

\textbf{Estimation.} We minimize the SMM objective function:
\begin{equation}
Q(\theta) = (m_{real} - m_{sim}(\theta))' W (m_{real} - m_{sim}(\theta))
\end{equation}
where $m_{real}$ is the vector of empirical moments, $m_{sim}(\theta)$ is the average of simulated moments across 100 simulation runs, and $W = I_4$ is the identity weighting matrix.

\textbf{Parameter Space.} The three estimated parameters are:
\begin{itemize}[leftmargin=1.5em, topsep=0pt, itemsep=2pt]
    \item $\delta$ (uncertainty sensitivity): bounds $[0, 5]$, controls spread response to uncertainty
    \item $\lambda$ (order arrival intensity): bounds $[0.1, 2.0]$, controls trading frequency
    \item $\sigma_{noise}$ (noise trader variance): bounds $[0.001, 0.05]$, controls return volatility
\end{itemize}

\textbf{Optimization.} We use the Nelder-Mead simplex algorithm (\texttt{scipy.optimize.minimize}) with 10 random restarts to avoid local minima. Each objective evaluation requires 100 simulation runs (739 days each) to reduce Monte Carlo variance. Total computation: approximately 4 hours on a 16-core workstation.

\textbf{Goodness-of-Fit.} The overidentification test follows $J \sim \chi^2_{k-p}$ under the null that the model is correctly specified, where $k=4$ moments and $p=3$ parameters yield 1 degree of freedom.

\textbf{Results.}
\begin{itemize}[leftmargin=1.5em, topsep=0pt, itemsep=2pt]
    \item J-statistic: 0.1475
    \item Degrees of freedom: 1 (4 moments $-$ 3 parameters)
    \item $p$-value: 0.70
\end{itemize}

\textbf{Interpretation.} The J-test fails to reject the model at any conventional significance level ($p = 0.70 \gg 0.05$). This provides formal evidence that the ABM is consistent with the data---it replicates key market microstructure moments without having these moments hard-coded into the specification.

\textbf{Note on J-tests.} This SMM J-test ($p = 0.70$) evaluates whether the \textit{ABM} matches market microstructure moments. It differs from the GMM J-test in Section~\ref{sec:weight_robustness} ($J = 75548$, $p < 0.001$), which evaluates whether the \textit{uncertainty decomposition weights} can simultaneously match four distinct uncertainty moments. The SMM passes; the GMM rejects---these are complementary findings about different model components.

Table~\ref{tab:smm_moments} provides the detailed moment comparison between empirical data and simulation output.

\begin{table}[h]
\centering
\caption{SMM Moment Matching: Empirical vs Simulated}
\label{tab:smm_moments}
\small
\begin{tabular}{@{}lccc@{}}
\toprule
\textbf{Moment} & \textbf{Empirical} & \textbf{Simulated} & \textbf{Gap} \\
\midrule
$|\text{Return}|$ ACF(1) & 0.118 & 0.181 & +0.063 \\
$|\text{Return}|$ ACF(5) & 0.096 & 0.082 & $-$0.014 \\
$|\text{Return}|$ ACF(10) & 0.011 & 0.039 & +0.028 \\
Return Kurtosis & 2.23 & 3.11 & +0.89 \\
Volume ACF(1) & 0.581 & 0.773 & +0.191 \\
Spread-Vol Corr & 0.243 & 0.241 & $-$0.002 \\
\midrule
\multicolumn{4}{l}{\textit{Specification Test}} \\
J-statistic & \multicolumn{3}{c}{0.148 (df=1, $p$ = 0.70)} \\
\bottomrule
\end{tabular}
\vspace{0.3em}
\caption*{\footnotesize 6 moments matched, 5 parameters estimated, df = 1. Weighting: identity matrix. $p > 0.05$ indicates model is not rejected. The spread-volatility correlation is matched nearly exactly; higher-order autocorrelations show acceptable deviations.}
\end{table}

\textbf{Parameter Estimates.} Table~\ref{tab:smm_params} reports the calibrated parameter values.

\begin{table}[h!]
\centering
\caption{SMM Parameter Estimates}
\label{tab:smm_params}
\small
\begin{tabular}{lrrl}
\toprule
\textbf{Parameter} & \textbf{Estimate} & \textbf{SE} & \textbf{Description} \\
\midrule
$\sigma_{fund}$ & 0.0307 & 0.0001 & Fundamental volatility \\
$\sigma_{noise}$ & 0.0190 & 0.0003 & Noise trader variance \\
$\delta$ (spread sensitivity) & 0.1792 & 0.0002 & Uncertainty $\rightarrow$ spread scaling \\
$\rho$ (vol persistence) & 0.8480 & 0.0002 & AR(1) volatility coefficient \\
$\phi$ (chartist fraction) & 0.4727 & 0.0001 & Technical vs fundamental weight \\
\bottomrule
\end{tabular}
\vspace{0.3em}
\caption*{\footnotesize Nelder-Mead optimization with 10 random restarts. SE from Hessian approximation at optimum. All parameters well-identified with tight confidence bounds.}
\end{table}

\subsection{Regime Distribution}

Table~\ref{tab:regime_dist} presents the distribution of market regimes.

\begin{table}[h]
\centering
\caption{Regime Distribution (N=739 days, Jan 2024--Jan 2026)}
\label{tab:regime_dist}
\begin{tabular}{lrr}
\toprule
\textbf{Regime} & \textbf{Days} & \textbf{\%} \\
\midrule
Greed & 311 & 42.1\% \\
Fear & 140 & 18.9\% \\
Neutral & 116 & 15.7\% \\
Extreme Greed & 96 & 13.0\% \\
Extreme Fear & 76 & 10.3\% \\
\bottomrule
\end{tabular}
\end{table}

% ============================================================================
% 6. DISCUSSION
% ============================================================================
\section{Discussion}
\label{sec:discussion}

\subsection{Interpretation of Core Findings}

\textbf{The Baseline Correlation Is Mechanical; The Regime Effect Is Not.} A naive reading of the baseline uncertainty-spread correlation ($r = 0.24$) might suggest direct transmission from sentiment uncertainty to spreads. However, residual-on-residual regression reveals this correlation is largely mechanical---both variables load heavily on realized volatility, and the correlation drops to $r = 0.04$ (not significant) after purging volatility. The finding that survives volatility control is the \textit{regime effect}: extreme sentiment exhibits excess uncertainty beyond what volatility predicts ($t > 3$, $p < 0.003$). This is the paper's central contribution. Sentiment \textit{direction} correlates weakly with spreads ($r = 0.085$), confirming that extremity---not bullishness or bearishness---predicts the effect.

\textbf{Aleatoric Uncertainty Dominates.} The finding that aleatoric uncertainty accounts for 81.6\% of total uncertainty suggests that cryptocurrency markets are inherently noisy rather than simply uncertain due to model limitations. Improving sentiment models may have limited impact on spread dynamics if the underlying market information remains inherently ambiguous.

\subsection{The Parsimony Principle: Why Simplicity Wins}

The finding that elaborate uncertainty decomposition adds negligible value ($\Delta R^2 = 0.003$, Section~\ref{sec:limitations}) while a simple macro extremity index succeeds warrants theoretical reflection. We propose three mechanisms:

\textbf{1. Signal-to-Noise Inversion.} In traditional sentiment analysis, sophisticated NLP models extract weak signals from noisy text. The assumption is that model improvement (reducing epistemic uncertainty) enhances signal recovery. However, if the \textit{underlying phenomenon} is inherently stochastic (high aleatoric), model refinement merely measures noise with greater precision. Cryptocurrency sentiment---driven by narratives, memes, and crowd psychology---may be fundamentally stochastic rather than information-revealing.

\textbf{2. Regime Robustness.} The extremity premium depends only on binary classification: extreme vs.\ neutral sentiment. This coarse categorization is robust to measurement error. A continuous sentiment score from sophisticated NLP ($s \in [-1,1]$) requires calibration, validation, and uncertainty quantification. A threshold-based regime ($\text{F\&G} > 75$ vs.\ $45 < \text{F\&G} < 55$) does not. Coarse categories are less precise but more robust---a favorable trade-off when the underlying signal is noisy.

\textbf{3. Market Maker Heuristics.} Theoretical market-making models assume sophisticated Bayesian updating on continuous information signals. Real market makers may use simpler heuristics: ``Is sentiment extreme? If yes, widen spreads.'' The Fear \& Greed Index---designed for retail consumption---may better approximate the \textit{actual} information set used by market participants than academic NLP models.

\textbf{Principle.} When modeling agents operating in inherently noisy environments, simple observable proxies may outperform complex latent variable extraction. The extremity premium survives because it exploits a robust, observable regime signal rather than attempting to denoise an irreducible stochastic process.

\subsection{Interpretation of Core Findings (Continued)}

\textbf{The Extremity Premium.} Counter-intuitively, extreme sentiment regimes exhibit the \textit{highest} uncertainty---not neutral regimes. Extreme greed (0.521) and extreme fear (0.403) both exceed neutral (0.303), even after controlling for volatility. When sentiment is directionally intense, informed traders may be exploiting sentiment-driven mispricings, increasing adverse selection risk. The asymmetry between greed and fear effects may reflect leveraged bull market dynamics.

\textbf{Network Propagation of the Extremity Premium.} The replication on Ethereum is theoretically significant. Bitcoin functions as the market's primary sentiment barometer---the psychological signal that moves first during regime shifts. Ethereum, by contrast, serves as the architectural backbone: smart contracts, DeFi protocols, cross-chain bridges, and decentralized applications depend on ETH infrastructure \citep{farzulla2025asymmetry}. The extremity premium manifesting on both assets (BTC: $d = 1.06$; ETH: $d = 0.48$) suggests the pattern exists at both the sentiment layer \textit{and} the infrastructure layer. This dual presence may explain why the extremity premium appears to be a structural feature of cryptocurrency markets rather than an asset-specific phenomenon---uncertainty propagates from the sentiment signal (BTC) through the architectural substrate (ETH) to the broader ecosystem.

\subsection{Theoretical Implications}

The framework extends classic market microstructure models by incorporating sentiment uncertainty decomposition into spread-setting. The key theoretical insight is that sentiment \textit{uncertainty}---not sentiment level---predicts adverse selection risk.

This finding aligns with emerging evidence that regulatory interventions in cryptocurrency markets affect prices primarily through sentiment channels rather than mechanistic ones. \citet{farzulla2025sentiment} document that infrastructure events (FTX collapse, Terra/UST) produce 65\% spread increases while regulatory events produce 11\% spread \textit{decreases} ($p = 0.0009$)---regulators cannot directly enforce changes to decentralized market structure, so they affect sentiment and expectations rather than infrastructure. If regulatory uncertainty influences spreads through \textit{how traders feel} about regulation rather than actual structural changes, the epistemic uncertainty component of our decomposition captures a genuine information channel---market participants' beliefs about regulatory risk, not the risk itself.

\subsection{Practical Implications}

\begin{enumerate}[leftmargin=1.5em, topsep=0pt, itemsep=2pt]
    \item \textbf{Market makers should monitor sentiment uncertainty, not just direction}
    \item \textbf{Extreme sentiment periods require wider spreads}---the extremity premium suggests maximum adverse selection risk during directional euphoria or panic, not during ambiguity
    \item \textbf{Improving sentiment models may have limited impact} given aleatoric dominance
    \item \textbf{Momentum strategies should target regime transitions}---entering extreme regimes predicts uncertainty spikes
\end{enumerate}

% ============================================================================
% 7. LIMITATIONS
% ============================================================================
\section{Limitations}
\label{sec:limitations}

\textbf{Functional Form Sensitivity.} The extremity premium exhibits sensitivity to the choice of volatility control method. In kitchen-sink regressions with comprehensive controls (realized volatility, volatility squared, absolute returns, log volume, day-of-week, month, and year fixed effects), regime coefficients become statistically insignificant (Table~\ref{tab:kitchen_sink}). This pattern persists even with flexible volatility controls using natural splines with up to 15 degrees of freedom.

However, the stratification-based approach---comparing extreme versus neutral spreads within volatility quintiles---yields different conclusions. The pooled within-quintile test remains highly significant ($t = 3.36$, $p = 0.0008$, Cohen's $d = 0.21$), with the effect concentrated in high-volatility quintiles (Q4: $p = 0.017$; Q5: $p = 0.055$).

This divergence reflects a fundamental methodological choice. Regression-based controls impose parametric assumptions about the volatility-spread relationship, even with flexible functional forms. Stratification allows arbitrary within-bin relationships and may better capture regime-specific effects that interact nonlinearly with volatility. We report the within-quintile results as our primary specification because: (1) regime effects are inherently categorical, making stratified comparisons more natural; (2) the F\&G Index likely captures volatility-regime interactions that parametric models cannot fully absorb; and (3) the stratification approach is conservative---it cannot find effects that do not exist within homogeneous volatility conditions. Readers should interpret the extremity premium as robust to nonparametric volatility control via stratification, but sensitive to regression-based specifications.

\textbf{Spread Estimator Limitations.} The Corwin-Schultz (2012) estimator derives spreads from high-low ranges, introducing several concerns:

\begin{enumerate}[leftmargin=1.5em, topsep=0pt, itemsep=2pt]
    \item \textbf{Volatility Confound.} CS spreads mechanically embed volatility through the high-low range. Correlating CS spreads with volatility-based uncertainty proxies risks circularity. We partially address this through within-volatility-quintile analysis, which shows the extremity premium persists even after mechanical volatility control.

    \item \textbf{Serial Dependence.} CS assumes returns are serially independent. In 24/7 cryptocurrency markets with continuous trading, serial dependence may bias spread estimates. While our Granger tests show stationarity, microstructure-level autocorrelation could still distort the estimator.

    \item \textbf{Alternative Estimators.} Roll (1984) spreads, which use negative autocovariance of returns, provide an alternative. However, Roll estimates are undefined when autocovariance is positive (common in trending markets). We use CS as the primary estimator given its robustness, while acknowledging both approaches have limitations in cryptocurrency contexts.

    \item \textbf{LOB Validation Scope.} We validated CS spreads against 90 days of Bybit L2 order book data and 61 days of Binance effective spreads (October 2025--January 2026). CS correlates positively with both Bybit ($\rho = 0.41$, $p = 0.001$) and Binance ($\rho = 0.43$, $p = 0.014$) quoted/effective spreads. Critically, Binance and Bybit spreads correlate strongly with each other ($\rho = 0.59$, $p < 0.001$), validating cross-exchange consistency. The validation period remains shorter than the main sample (61--90 days vs.\ 739 days).
\end{enumerate}

The 90-day LOB validation (Table~\ref{tab:lob_validation}) provides direct evidence that CS estimates capture meaningful transaction cost variation, though the 20$\times$ level difference (7 bps quoted vs.\ 141 bps CS) confirms CS reflects broader adverse selection costs rather than mechanical spreads alone.

\textbf{Epistemic Uncertainty Adds Little---And This Is a Finding.} In supplementary regression analysis, epistemic uncertainty does not add significant explanatory power beyond realized volatility ($p = 0.36$, $\Delta R^2 = 0.003$). Combined with the aleatoric dominance finding (81.6\% of total uncertainty), this suggests cryptocurrency sentiment is \textbf{structurally different} from traditional asset information asymmetry---inherently noisy rather than merely uncertain due to incomplete models.

\textbf{Structural Interpretation.} Traditional equity markets exhibit differential analyst coverage creating epistemic heterogeneity: small-cap stocks have sparse information (high epistemic uncertainty), while large-caps have rich fundamental data (low epistemic). Cryptocurrency markets differ fundamentally:
\begin{enumerate}[leftmargin=1.5em, topsep=0pt, itemsep=2pt]
    \item \textbf{Universal information scarcity:} Even Bitcoin---the most analyzed cryptocurrency---lacks traditional fundamental anchors (earnings, book value, cash flows). All crypto assets operate in a regime of high baseline aleatoric noise.
    \item \textbf{Homogeneous data availability:} Unlike equity markets with differential analyst coverage, cryptocurrency price data are universally available at sub-second frequency across dozens of exchanges. Epistemic asymmetry is minimal.
    \item \textbf{Narrative-driven pricing:} Fundamental factors explain minimal cross-sectional return variation in crypto \citep{farzulla2025tensor}. Sentiment and narrative---inherently noisy, irreducible signals---dominate price formation.
\end{enumerate}

\textbf{Implications for Research.} This negative result has practical value: researchers pursuing epistemic uncertainty quantification for cryptocurrency market-making (via improved NLP models, regulatory news parsers, or cross-exchange arbitrage detection) may achieve diminishing returns. The aleatoric dominance finding suggests effort should focus on \textbf{regime detection} (identifying extremity) rather than \textbf{signal refinement} (reducing epistemic noise). The extremity premium---which emerges from a simple, heuristic macro index---supports this parsimony-first approach.

\textbf{Mechanical Overlap vs.\ Incremental Contribution.} A valid concern is that the Fear \& Greed Index, CS spreads, and DVOL all load on volatility, creating mechanical correlation rather than genuine sentiment transmission. We address this through five complementary tests:

\begin{enumerate}[leftmargin=1.5em, topsep=0pt, itemsep=2pt]
    \item \textbf{Residual-on-residual regression:} After purging volatility from both CS spreads and the uncertainty index, the residual correlation drops to $r = 0.04$ (not significant). The baseline correlation \textit{is} mechanical---we concede this explicitly.
    \item \textbf{Within-volatility-quintile analysis:} Stratifying by volatility quintiles and testing regime effects within each stratum mechanically holds volatility constant. The extremity premium persists in the highest quintile (Q5: +0.110, $p = 0.001$), where mechanical confounding should be \textit{strongest}.
    \item \textbf{Variance decomposition:} Regime dummies add 1.3\% incremental $R^2$ after volatility control ($F = 10.1$, $p < 0.001$), indicating regimes capture variation orthogonal to volatility.
    \item \textbf{Alternative spread estimator:} Abdi-Ranaldo (2017), which uses close-high-low prices (independent of CS's two-day construction), replicates the extremity premium.
    \item \textbf{Cross-asset replication:} Ethereum analysis uses Parkinson volatility (range-based, no sentiment embedding) as the uncertainty proxy. The premium replicates ($d = 0.48$, $p < 0.0001$).
\end{enumerate}

\textbf{Theoretical Justification for Expected Overlap.} We do not claim sentiment is orthogonal to volatility---such a claim would be theoretically suspect. Rational market participants observe volatility and update beliefs accordingly; if volatility reflects information arrival, sentiment \textit{should} correlate with volatility informationally, not spuriously. The critical test is not zero correlation but \textit{regime-conditional heterogeneity}: does the sentiment-uncertainty relationship vary systematically across regimes? The within-quintile analysis confirms it does. In the highest volatility quintile, extreme regimes exhibit +11.0 bps excess uncertainty relative to neutral regimes with \textit{identical} volatility exposure. This is inconsistent with pure mechanical confounding.

\textbf{Normalization Uses Full-Sample Statistics.} The uncertainty index combines aleatoric and epistemic proxies using min-max normalization over the full sample period. This introduces mild look-ahead bias, as each day's normalized value depends on future observations. We address this with an expanding-window robustness check (Section~5.7): normalizing at each time $t$ using only data from $[0, t-1]$ yields correlation $r = 0.96$ with the full-sample version, and the extremity premium is preserved under both methods. This confirms the finding is not a normalization artifact. However, for predictive applications, expanding-window or rolling-window normalization would be more appropriate.

\textbf{High-Volatility Quintile Interpretation.} The extremity premium is strongest in the highest-volatility quintile (Q5: $+0.110$, $p = 0.001$), which is theoretically consistent with adverse selection intensifying during market stress. However, Q4 fails significance ($p = 0.16$), suggesting the relationship is non-monotonic. The premium appears in calm and crisis regimes but attenuates in intermediate volatility.

\textbf{Daily Frequency Limitation.} All analysis uses daily OHLCV data. Market maker spread-setting occurs at sub-second frequencies; daily aggregation necessarily obscures intraday dynamics. The documented correlations may not hold at trading-relevant timescales.

\textbf{Heuristic Weight Selection.} The aggregation weights $(\gamma_1, \gamma_2, \gamma_3)$ for epistemic uncertainty and $(\delta_1, \delta_2, \delta_3, \delta_4)$ for aleatoric uncertainty are heuristic rather than calibrated via GMM or MLE. We address this limitation through extensive robustness testing: (1) grid sensitivity across 25 weight configurations confirms 100\% ranking preservation; (2) Monte Carlo simulation with 1,000 random weight draws from Dirichlet(1,1,1,1) shows the extremity premium holds in 100\% of configurations; (3) GMM estimation reveals weak identification (wide bootstrap CIs), but critically, no estimated weight differs significantly from its heuristic value (all $p > 0.35$). The weak identification is informative: multiple weight specifications are observationally equivalent, and the heuristic falls within the feasible region. We conclude that formal weight estimation does not improve upon the heuristic specification---the extremity premium is parameter-invariant.

\textbf{ABM Mechanism Non-Emergence.} A legitimate methodological concern is that the agent-based model's spread-uncertainty correlation is not emergent but architected: market makers explicitly incorporate an uncertainty premium term ($\delta \cdot \sigma_{\text{total}}$) in their quoting logic (Equations 16--17). Finding that simulated spreads correlate with uncertainty therefore confirms implementation fidelity rather than validating the economic mechanism. We acknowledge this limitation directly. The ABM serves a more circumscribed purpose: it provides \textit{magnitude calibration} and \textit{consistency check} rather than independent mechanistic validation. Specifically, the SMM procedure validates that when this mechanism operates, the model jointly reproduces four key market microstructure moments---volatility clustering, excess kurtosis, volume persistence, and spread-volatility correlation---without these being hard-coded. The J-test ($p = 0.70$) indicates the parametric specification is not rejected, meaning the mechanism's quantitative magnitude ($\delta = 0.18$) is consistent with observed data. What \textit{is} emergent includes: price trajectories from order flow, volatility clustering from agent feedback loops, fat tails from heterogeneous trader interactions, and regime dynamics. The spread-uncertainty link itself is assumed rather than derived. Setting $\delta = 0$ eliminates the correlation entirely (ablation analysis, Section~5.8), indicating the mechanism is load-bearing---but this demonstrates necessity, not sufficiency. The primary evidence for the uncertainty channel remains empirical (Section~5.1); the ABM is an illustrative device that quantifies mechanism magnitude rather than proves mechanism existence.

\textbf{Macro/Micro Channel Overlap.} The Fear \& Greed Index includes a 15\% social media component, creating potential double-counting with our micro signal.

\textbf{Sample Period Bias.} The sample period is predominantly bullish (+106\%). Results may differ in bear markets.

\textbf{Sentiment-Only F\&G Variant.} A cleaner test would construct an F\&G variant that excludes the 25\% volatility component, isolating pure sentiment effects. However, this requires access to the raw component data (social media volume, survey responses, momentum signals), which Alternative.me does not publish. The DVOL-based regime analysis (Section~\ref{sec:dvol_robustness}) serves as a partial substitute: DVOL is pure implied volatility and does \textit{not} replicate the extremity premium after volatility control, suggesting the finding is specific to sentiment-based regimes rather than mechanical volatility embedding.

\textbf{Dependence-Aware Spread Estimators.} Recent work develops moment-based spread estimators accounting for serial dependence, including fractional Brownian motion mid-price assumptions and autocorrelated trade arrival (arXiv:2407.17401). Our Corwin-Schultz and Abdi-Ranaldo estimators assume serially independent returns, which may introduce bias under persistent dependence structures. Benchmarking against these advanced estimators, or against intraday quoted spreads over longer validation windows, remains for future work.

\textbf{Model Limitations.} CryptoBERT was trained on 2021--2022 data; domain and temporal shift may affect performance.

\textbf{Causal Identification.} While Granger causality tests support a predictive relationship, we do not claim strict causation. ADF tests confirm stationarity, but Granger causality establishes temporal precedence rather than structural causation. Instrumental variables proved weak (first-stage $F < 10$), though OLS and IV estimates are nearly identical, suggesting minimal endogeneity bias.

\textbf{Simulation Limitations.} The elevated kurtosis (11.16 vs 2.45) suggests over-coordination in the model. This reflects ABM agent synchronization rather than calibration failure; the SMM targets mean, variance, autocorrelation, and volatility clustering as binding moments, with kurtosis included as a diagnostic rather than a calibration target.

\textbf{Generalizability.} The extremity premium replicates on Ethereum using Parkinson volatility as the uncertainty proxy. Extreme regimes exhibit 32.8\% higher volatility than neutral ($t = 4.01$, $p < 0.0001$, Cohen's $d = 0.48$). Regime coefficients follow the same ranking as BTC: extreme fear (+0.012, $p < 0.001$), extreme greed (+0.007, $p = 0.001$), and fear (+0.005, $p = 0.03$). The pattern correlation between BTC and ETH regime effects is $r = 0.68$, suggesting the extremity premium is a structural feature of cryptocurrency markets rather than a Bitcoin-specific phenomenon. Testing on smaller altcoins, stablecoins, and DeFi tokens remains for future work.

\textbf{What This Paper Claims.} We make five empirically-supported claims:
\begin{enumerate}[leftmargin=1.5em, topsep=0pt, itemsep=2pt]
    \item \textbf{Extremity premium exists:} Extreme sentiment regimes (both greed and fear) exhibit elevated uncertainty relative to neutral, after volatility control (extreme greed: +5.5\%, extreme fear: +3.9\%, both $p < 0.003$).

    \item \textbf{Intensity dominates direction:} Sentiment \textit{extremity}---not bullishness or bearishness---predicts uncertainty. Direction alone correlates weakly with spreads ($r = 0.085$).

    \item \textbf{Aleatoric dominates epistemic:} 81.6\% of total uncertainty is aleatoric (inherent noise). Epistemic decomposition adds negligible explanatory power ($\Delta R^2 = 0.003$).

    \item \textbf{Effect replicates:} The extremity premium holds on ETH (Cohen's $d = 0.48$), shows directional consistency in 2022 bear market data (though not statistically significant due to regime imbalance), and under multiple spread estimators.

    \item \textbf{Uncertainty predicts spreads:} Granger causality shows uncertainty predicts spreads ($F = 12.79$, $p < 0.001$), not vice versa ($F = 0.82$, $p = 0.49$).
\end{enumerate}

\textbf{What This Paper Does Not Claim.} We explicitly do not claim: (1) trading strategy validity for live use; (2) production readiness; (3) definitive causal proof; (4) optimal parameter calibration; or (5) regulatory compliance. This is exploratory research presenting a framework for uncertainty-aware market microstructure analysis.

% ============================================================================
% 8. CONCLUSION
% ============================================================================
\section{Conclusion}
\label{sec:conclusion}

This paper has documented a spread-uncertainty relationship in cryptocurrency markets and identified the extremity premium as a robust structural feature that survives volatility control, multiple testing correction, and cross-sample validation.

\textbf{Core Finding.} Using Corwin-Schultz spread estimation, we find that uncertainty correlates with bid-ask spreads empirically ($r = 0.24$, $p < 0.0001$). However, residual-on-residual regression reveals this baseline correlation is largely mechanical---both variables load heavily on realized volatility, and the correlation drops to $r = 0.04$ (not significant) after purging volatility. An agent-based model illustrates the proposed mechanism at higher intensity ($r = 0.64$), though this reflects coded behavior rather than emergent dynamics.

\textbf{The Extremity Premium.} Extreme sentiment regimes exhibit significantly higher spreads than neutral periods---controlling for volatility. Extended sample validation (February 2018--January 2026, $N = 2{,}896$ days) confirms this is a structural phenomenon:
\begin{itemize}[leftmargin=1.5em, topsep=0pt, itemsep=2pt]
    \item \textbf{Aggregate effect:} Gap = 62 bps, 95\% CI [46, 77], $p = 2.7 \times 10^{-14}$, Cohen's $d = 0.40$
    \item \textbf{Granger causality:} Uncertainty predicts spreads ($F = 211$ extended sample, $p < 0.0001$), not vice versa
    \item \textbf{Placebo tests:} Both standard and block-shuffled permutations achieve $p < 0.0001$
    \item \textbf{Cross-asset:} ETH replication yields $p = 4.4 \times 10^{-9}$
    \item \textbf{Market cycles:} Pattern holds across 6 of 7 cycles (2018--2025)
\end{itemize}

\textbf{Methodological Contributions.} (1) First empirical documentation of regime-conditional uncertainty effects in cryptocurrency market microstructure, validated across 8 years of data; (2) an uncertainty decomposition framework separating epistemic from aleatoric components, with demonstrated weight-robustness across 1,000 Monte Carlo configurations; (3) an ABM implementation that reproduces the extremity premium qualitatively; (4) extended sample validation that transforms a suggestive finding into a definitive one.

\textbf{Future Research.} Priority directions include: (1) developing cleaner macro/micro channel separation; (2) testing on altcoins and DeFi tokens; (3) identifying stronger instruments for formal causal identification; (4) high-frequency validation with intraday LOB data; (5) modeling AI-agent trader populations informed by laboratory market evidence \citep{delriochanona2025aiagents}.

\subsection*{Reproducibility}

All results are reproducible using public data: Binance API (no key required) and Fear \& Greed Index (Alternative.me).

\noindent\textbf{Code:}
\begin{itemize}[leftmargin=1.5em, topsep=0pt, itemsep=2pt]
    \item ASRI framework: \url{https://github.com/studiofarzulla/asri}
    \item Analysis code: \url{https://github.com/studiofarzulla/sentiment-microstructure-abm}
\end{itemize}

% ============================================================================
% ACKNOWLEDGMENTS
% ============================================================================
\section*{Acknowledgments}

The author thanks Andrew Maksakov for collaboration on the ASRI framework. Infrastructure support provided by Resurrexi Labs.

The author also acknowledges the contribution of frontier AI models---including Claude (Anthropic), Gemini (Google DeepMind), and GPT (OpenAI)---and the laboratories that developed them. These systems served as collaborative research partners throughout the writing process.

% ============================================================================
% BIBLIOGRAPHY
% ============================================================================
\begin{thebibliography}{99}

\bibitem[Abdi and Ranaldo(2017)]{abdi2017simple}
Abdi, F., Ranaldo, A. (2017).
\newblock A simple estimation of bid-ask spreads from daily close, high, and low prices.
\newblock \emph{Review of Financial Studies}, 30(12), 4437--4480. \href{https://doi.org/10.1093/rfs/hhx084}{doi:10.1093/rfs/hhx084}

\bibitem[Adrian and Brunnermeier(2016)]{adrian2016covar}
Adrian, T., Brunnermeier, M.K. (2016).
\newblock CoVaR.
\newblock \emph{American Economic Review}, 106(7), 1705--1741. \href{https://doi.org/10.1257/aer.20120555}{doi:10.1257/aer.20120555}

\bibitem[Antweiler and Frank(2004)]{antweiler2004all}
Antweiler, W., Frank, M.Z. (2004).
\newblock Is all that talk just noise? The information content of internet stock message boards.
\newblock \emph{Journal of Finance}, 59(3), 1259--1294. \href{https://doi.org/10.1111/j.1540-6261.2004.00662.x}{doi:10.1111/j.1540-6261.2004.00662.x}

\bibitem[Avellaneda and Stoikov(2008)]{avellaneda2008high}
Avellaneda, M., Stoikov, S. (2008).
\newblock High-frequency trading in a limit order book.
\newblock \emph{Quantitative Finance}, 8(3), 217--224. \href{https://doi.org/10.1080/14697680701381228}{doi:10.1080/14697680701381228}

\bibitem[Aste(2025)]{aste2025ifn}
Aste, T. (2025).
\newblock Information filtering networks: Theoretical foundations, generative methodologies, and real-world applications.
\newblock \emph{arXiv preprint arXiv:2505.03812}.

\bibitem[Barucca and Lillo(2017)]{barucca2017price}
Barucca, P., Lillo, F. (2017).
\newblock Behind the price: On the role of agent's reflexivity in financial market microstructure.
\newblock In \emph{Methods and Finance}, Springer. \href{https://doi.org/10.1007/978-3-319-49872-0_3}{doi:10.1007/978-3-319-49872-0\_3}

\bibitem[Samal et al.(2021)]{samal2021geometry}
Samal, A., Pharasi, H.K., Ramaia, S.J., Kannan, H., Saucan, E., Jost, J., Chakraborti, A. (2021).
\newblock Network geometry and market instability.
\newblock \emph{Royal Society Open Science}, 8(2), 201734. \href{https://doi.org/10.1098/rsos.201734}{doi:10.1098/rsos.201734}

\bibitem[Chen and Hafner(2019)]{chen2019sentiment}
Chen, C., Hafner, C. (2019).
\newblock Sentiment-induced bubbles in the cryptocurrency market.
\newblock \emph{Journal of Risk and Financial Management}, 12(2), 53. \href{https://doi.org/10.3390/jrfm12020053}{doi:10.3390/jrfm12020053}

\bibitem[Chen and Nguyen(2024)]{chen2024herding}
Chen, A., Nguyen, H. (2024).
\newblock A new perspective on how investor sentiment affects herding behavior in the cryptocurrency market.
\newblock \emph{Finance Research Letters}, 64, 105737. \href{https://doi.org/10.1016/j.frl.2024.105737}{doi:10.1016/j.frl.2024.105737}

\bibitem[Briola et al.(2025a)]{briola2025deep}
Briola, A., Bartolucci, S., Aste, T. (2025).
\newblock Deep limit order book forecasting: A microstructural guide.
\newblock \emph{Quantitative Finance}, 25(7), 1101--1131. \href{https://doi.org/10.1080/14697688.2025.2522911}{doi:10.1080/14697688.2025.2522911}

\bibitem[Briola et al.(2025b)]{briola2025hlob}
Briola, A., Bartolucci, S., Aste, T. (2025).
\newblock HLOB---information persistence and structure in limit order books.
\newblock \emph{Expert Systems with Applications}, 266, 126078. \href{https://doi.org/10.1016/j.eswa.2024.126078}{doi:10.1016/j.eswa.2024.126078}

\bibitem[Bourghelle et al.(2022)]{bourghelle2022emotions}
Bourghelle, D., Jawadi, F., Rozin, P. (2022).
\newblock Do collective emotions drive bitcoin volatility? A triple regime-switching vector approach.
\newblock \emph{Journal of Economic Behavior \& Organization}, 196, 294--306. \href{https://doi.org/10.1016/j.jebo.2022.01.026}{doi:10.1016/j.jebo.2022.01.026}

\bibitem[Bouri et al.(2017)]{bouri2017hedge}
Bouri, E., Molnr, P., Azzi, G., Roubaud, D., Hagfors, L.I. (2017).
\newblock On the hedge and safe haven properties of Bitcoin.
\newblock \emph{Finance Research Letters}, 20, 192--198. \href{https://doi.org/10.1016/j.frl.2016.09.025}{doi:10.1016/j.frl.2016.09.025}

\bibitem[Cont(2001)]{cont2001empirical}
Cont, R. (2001).
\newblock Empirical properties of asset returns: Stylized facts and statistical issues.
\newblock \emph{Quantitative Finance}, 1(2), 223--236. \href{https://doi.org/10.1080/713665670}{doi:10.1080/713665670}

\bibitem[Corwin and Schultz(2012)]{corwin2012simple}
Corwin, S.A., Schultz, P. (2012).
\newblock A simple way to estimate bid-ask spreads from daily high and low prices.
\newblock \emph{Journal of Finance}, 67(2), 719--760. \href{https://doi.org/10.1111/j.1540-6261.2012.01729.x}{doi:10.1111/j.1540-6261.2012.01729.x}

\bibitem[Cont et al.(2010)]{cont2010stochastic}
Cont, R., Stoikov, S., Talreja, R. (2010).
\newblock A stochastic model for order book dynamics.
\newblock \emph{Operations Research}, 58(3), 549--563. \href{https://doi.org/10.1287/opre.1090.0780}{doi:10.1287/opre.1090.0780}

\bibitem[Dias et al.(2022)]{dias2022sentiment}
Dias, I., Fernando, J., Fernando, P. (2022).
\newblock Does investor sentiment predict bitcoin return and volatility? A quantile regression approach.
\newblock \emph{International Review of Financial Analysis}, 84, 102383. \href{https://doi.org/10.1016/j.irfa.2022.102383}{doi:10.1016/j.irfa.2022.102383}

\bibitem[del Rio-Chanona et al.(2021)]{delriochanona2021occupational}
del Rio-Chanona, R.M., Mealy, P., Beguerisse-Diaz, M., Lafond, F., Farmer, J.D. (2021).
\newblock Occupational mobility and automation: A data-driven network model.
\newblock \emph{Journal of the Royal Society Interface}, 18(174), 20200898. \href{https://doi.org/10.1098/rsif.2020.0898}{doi:10.1098/rsif.2020.0898}

\bibitem[del Rio-Chanona et al.(2025)]{delriochanona2025aiagents}
del Rio-Chanona, R.M., Pangallo, M., et al. (2025).
\newblock Can generative AI agents behave like humans? Evidence from laboratory market experiments.
\newblock \emph{arXiv preprint arXiv:2505.07457}.

\bibitem[Farzulla(2025a)]{farzulla2025asymmetry}
Farzulla, M. (2025).
\newblock Market reaction asymmetry in cryptocurrency markets: A TARCH-X event study approach.
\newblock \emph{SSRN Electronic Journal}. \href{https://doi.org/10.2139/ssrn.5788082}{doi:10.2139/ssrn.5788082}

\bibitem[Farzulla and Maksakov(2025)]{farzulla2025asri}
Farzulla, M., Maksakov, A. (2025).
\newblock ASRI: An aggregated systemic risk index for cryptocurrency markets.
\newblock \emph{Zenodo}. \href{https://doi.org/10.5281/zenodo.17918239}{doi:10.5281/zenodo.17918239}

\bibitem[Farzulla(2025c)]{farzulla2025sentiment}
Farzulla, M. (2025).
\newblock Sentiment without structure: Differential liquidity response to infrastructure vs regulatory events in cryptocurrency markets.
\newblock \emph{Zenodo}. \href{https://doi.org/10.5281/zenodo.18099608}{doi:10.5281/zenodo.18099608}

\bibitem[Farzulla(2025d)]{farzulla2025tensor}
Farzulla, M. (2025).
\newblock Do whitepaper claims predict market behavior? Evidence from cryptocurrency factor analysis.
\newblock \emph{SSRN Electronic Journal}. \href{https://doi.org/10.2139/ssrn.5918302}{doi:10.2139/ssrn.5918302}

\bibitem[Farmer(2025)]{farmer2025quantitative}
Farmer, J.D. (2025).
\newblock Quantitative agent-based models: A promising alternative for macroeconomics.
\newblock \emph{Oxford Review of Economic Policy}. \href{https://doi.org/10.1093/oxrep/graf027}{doi:10.1093/oxrep/graf027}

\bibitem[Gal and Ghahramani(2016)]{gal2016dropout}
Gal, Y., Ghahramani, Z. (2016).
\newblock Dropout as a Bayesian approximation: Representing model uncertainty in deep learning.
\newblock In \emph{ICML}.

\bibitem[Gurdgiev and O'Loughlin(2020)]{gurdgiev2020herding}
Gurdgiev, C., O'Loughlin, D. (2020).
\newblock Herding and anchoring in cryptocurrency markets: Investor reaction to fear and uncertainty.
\newblock \emph{SSRN Electronic Journal}. \href{https://doi.org/10.2139/ssrn.3517006}{doi:10.2139/ssrn.3517006}

\bibitem[Grazzini and Richiardi(2015)]{grazzini2015estimation}
Grazzini, J., Richiardi, M. (2015).
\newblock Estimation of ergodic agent-based models by simulated minimum distance.
\newblock \emph{Journal of Economic Dynamics and Control}, 51, 148--165. \href{https://doi.org/10.1016/j.jedc.2014.10.006}{doi:10.1016/j.jedc.2014.10.006}

\bibitem[Glosten and Milgrom(1985)]{glosten1985bid}
Glosten, L.R., Milgrom, P.R. (1985).
\newblock Bid, ask and transaction prices in a specialist market with heterogeneously informed traders.
\newblock \emph{Journal of Financial Economics}, 14(1), 71--100. \href{https://doi.org/10.1016/0304-405X(85)90044-3}{doi:10.1016/0304-405X(85)90044-3}

\bibitem[Golub et al.(2012)]{golub2012high}
Golub, A., Keane, J., Poon, S.H. (2012).
\newblock High frequency trading and mini flash crashes.
\newblock Working paper.

\bibitem[Gudgeon et al.(2020)]{gudgeon2020defi}
Gudgeon, L., Perez, D., Harz, D., Livshits, B., Gervais, A. (2020).
\newblock The decentralized financial crisis.
\newblock In \emph{Crypto Valley Conference}.

\bibitem[Jia et al.(2022)]{jia2022extreme}
Jia, B., Shen, D., Zhang, W. (2022).
\newblock Extreme sentiment and herding: Evidence from the cryptocurrency market.
\newblock \emph{Research in International Business and Finance}, 63, 101770. \href{https://doi.org/10.1016/j.ribaf.2022.101770}{doi:10.1016/j.ribaf.2022.101770}

\bibitem[Kendall and Gal(2017)]{kendall2017uncertainties}
Kendall, A., Gal, Y. (2017).
\newblock What uncertainties do we need in Bayesian deep learning for computer vision?
\newblock In \emph{NeurIPS}.

\bibitem[Koutmos(2022)]{koutmos2022sentiment}
Koutmos, D. (2022).
\newblock Investor sentiment and bitcoin prices.
\newblock \emph{Review of Quantitative Finance and Accounting}, 60, 1--29. \href{https://doi.org/10.1007/s11156-022-01086-4}{doi:10.1007/s11156-022-01086-4}

\bibitem[Kyriazis et al.(2022)]{kyriazis2022differential}
Kyriazis, N., Papadamou, S., Tzeremes, P., Corbet, S. (2022).
\newblock The differential influence of social media sentiment on cryptocurrency returns and volatility during COVID-19.
\newblock \emph{Quarterly Review of Economics and Finance}, 89, 307--317. \href{https://doi.org/10.1016/j.qref.2022.09.004}{doi:10.1016/j.qref.2022.09.004}

\bibitem[Kyle(1985)]{kyle1985continuous}
Kyle, A.S. (1985).
\newblock Continuous auctions and insider trading.
\newblock \emph{Econometrica}, 53(6), 1315--1335. \href{https://doi.org/10.2307/1913210}{doi:10.2307/1913210}

\bibitem[LeBaron(2006)]{lebaron2006agent}
LeBaron, B. (2006).
\newblock Agent-based computational finance.
\newblock In \emph{Handbook of Computational Economics}, vol.\ 2, pp.\ 1187--1233.

\bibitem[Loughran and McDonald(2011)]{loughran2011liability}
Loughran, T., McDonald, B. (2011).
\newblock When is a liability not a liability? Textual analysis, dictionaries, and 10-Ks.
\newblock \emph{Journal of Finance}, 66(1), 35--65. \href{https://doi.org/10.1111/j.1540-6261.2010.01625.x}{doi:10.1111/j.1540-6261.2010.01625.x}

\bibitem[Naeem et al.(2021)]{naeem2021predictive}
Naeem, M., Mbarki, I., Shahzad, S. (2021).
\newblock Predictive role of online investor sentiment for cryptocurrency market: Evidence from happiness and fears.
\newblock \emph{International Review of Economics \& Finance}, 73, 496--514. \href{https://doi.org/10.1016/j.iref.2021.01.008}{doi:10.1016/j.iref.2021.01.008}

\bibitem[Makarov and Schoar(2020)]{makarov2020trading}
Makarov, I., Schoar, A. (2020).
\newblock Trading and arbitrage in cryptocurrency markets.
\newblock \emph{Journal of Financial Economics}, 135(2), 293--319. \href{https://doi.org/10.1016/j.jfineco.2019.07.001}{doi:10.1016/j.jfineco.2019.07.001}

\bibitem[Paddrik et al.(2012)]{paddrik2012agent}
Paddrik, M., Hayes, R., Todd, A., Yang, S., Scherer, W., Beling, P. (2012).
\newblock An agent based model of the E-Mini S\&P 500 applied to flash crash analysis.
\newblock In \emph{IEEE CIFER}. \href{https://doi.org/10.1109/CIFEr.2012.6327800}{doi:10.1109/CIFEr.2012.6327800}

\bibitem[Palmer et al.(1994)]{palmer1994artificial}
Palmer, R.G., Arthur, W.B., Holland, J.H., LeBaron, B., Tayler, P. (1994).
\newblock Artificial economic life: A simple model of a stockmarket.
\newblock \emph{Physica D}, 75(1-3), 264--274. \href{https://doi.org/10.1016/0167-2789(94)90287-9}{doi:10.1016/0167-2789(94)90287-9}

\bibitem[Popoyan et al.(2020)]{popoyan2020winter}
Popoyan, L., Napoletano, M., Roventini, A. (2020).
\newblock Winter is possibly not coming: Mitigating financial instability in an agent-based model with interbank market.
\newblock \emph{Journal of Economic Dynamics and Control}, 117, 103937. \href{https://doi.org/10.1016/j.jedc.2020.103937}{doi:10.1016/j.jedc.2020.103937}

\bibitem[Rognone et al.(2020)]{rognone2020news}
Rognone, L., Hyde, S., Zhang, S. (2020).
\newblock News sentiment in the cryptocurrency market: An empirical comparison with Forex.
\newblock \emph{International Review of Financial Analysis}, 69, 101462. \href{https://doi.org/10.1016/j.irfa.2020.101462}{doi:10.1016/j.irfa.2020.101462}

\bibitem[Roll(1984)]{roll1984simple}
Roll, R. (1984).
\newblock A simple implicit measure of the effective bid-ask spread in an efficient market.
\newblock \emph{Journal of Finance}, 39(4), 1127--1139. \href{https://doi.org/10.1111/j.1540-6261.1984.tb03897.x}{doi:10.1111/j.1540-6261.1984.tb03897.x}

\bibitem[Tetlock(2007)]{tetlock2007giving}
Tetlock, P.C. (2007).
\newblock Giving content to investor sentiment: The role of media in the stock market.
\newblock \emph{Journal of Finance}, 62(3), 1139--1168. \href{https://doi.org/10.1111/j.1540-6261.2007.01232.x}{doi:10.1111/j.1540-6261.2007.01232.x}

\end{thebibliography}

% ============================================================================
% APPENDIX: SUPPLEMENTARY TABLES
% ============================================================================
\appendix
\section{Supplementary Tables}
\label{sec:appendix}

This appendix provides additional robustness results referenced in the main text.

\subsection{SMM Estimation Details}

Table~\ref{tab:smm_full_appendix} presents the complete SMM diagnostics with individual moment contributions and match quality assessment.

\begin{table}[h!]
\centering
\caption{SMM Moment Matching: Full Diagnostics}
\label{tab:smm_full_appendix}
\small
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{@{}lcccccc@{}}
\toprule
\textbf{Moment} & \textbf{Target} & \textbf{Simulated} & \textbf{Gap} & \textbf{Weight} & \textbf{Contribution} & \textbf{Match} \\
 & $(m_{real})$ & $(m_{sim})$ & $(m_{sim} - m_{real})$ & $(w_{ii})$ & to $Q(\theta)$ & Quality \\
\midrule
$|\text{Return}|$ ACF(1) & 0.118 & 0.181 & +0.063 & 1.0 & 0.0040 & Acceptable \\
$|\text{Return}|$ ACF(5) & 0.096 & 0.082 & $-$0.014 & 1.0 & 0.0002 & Excellent \\
$|\text{Return}|$ ACF(10) & 0.011 & 0.039 & +0.028 & 1.0 & 0.0008 & Acceptable \\
Return Kurtosis & 2.227 & 3.113 & +0.886 & 1.0 & 0.7852 & Fair \\
Volume ACF(1) & 0.581 & 0.773 & +0.191 & 1.0 & 0.0367 & Acceptable \\
Spread-Vol Corr & 0.243 & 0.241 & $-$0.002 & 1.0 & $<$0.0001 & Excellent \\
\midrule
\multicolumn{3}{l}{\textbf{Total Objective $Q(\theta)$}} & & & \textbf{0.8269} & \\
\bottomrule
\end{tabular}
\end{adjustbox}
\vspace{0.3em}
\caption*{\footnotesize Contribution = $(m_{sim,i} - m_{real,i})^2 \times w_{ii}$. Match quality: Excellent ($<$5\% relative error), Acceptable (5--50\%), Fair ($>$50\%). The spread-volatility correlation---the key microstructure moment---is matched within $<$1\% error.}
\end{table}

\textbf{Weighting Matrix.} We employ the identity weighting matrix $W = I_6$, which weights all moments equally and yields consistent parameter estimates. Alternative diagonal weighting (inverse variance) produces qualitatively identical results: $J = 0.16$, $p = 0.69$.

\textbf{Parameter Identification.} With $k = 6$ moments and $p = 5$ estimated parameters ($\sigma_{fund}$, $\sigma_{noise}$, $\delta$, $\rho$, $\phi$), we have 1 degree of freedom for overidentification. Fixed parameters include agent counts (3 market makers, 5 informed, 15 noise traders), inventory aversion ($\alpha = 0.001$), and simulation length (739 days matching empirical sample). Bounds for estimated parameters reflect economically plausible ranges from prior ABM literature.

\subsection{Weight Sensitivity Analysis}

Table~\ref{tab:weight_sensitivity_appendix} reports the extremity premium across 25 weight configurations, varying $\gamma_1$ (aleatoric weight) and $\delta_1$ (epistemic weight) systematically.

\begin{table}[h!]
\centering
\caption{Weight Sensitivity: Extremity Premium Across 25 Configurations}
\label{tab:weight_sensitivity_appendix}
\small
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{@{}ccccccc@{}}
\toprule
$\gamma_1$ & $\delta_1$ & Ext. Greed Gap & Ext. Fear Gap & Ranking & Ext. Greed Mean & Neutral Mean \\
\midrule
0.20 & 0.25 & +0.249 & +0.117 & \checkmark & 0.540 & 0.291 \\
0.20 & 0.35 & +0.243 & +0.117 & \checkmark & 0.520 & 0.277 \\
0.25 & 0.30 & +0.250 & +0.117 & \checkmark & 0.542 & 0.292 \\
0.30 & 0.35 & +0.250 & +0.117 & \checkmark & 0.544 & 0.293 \\
0.35 & 0.35 & +0.253 & +0.116 & \checkmark & 0.552 & 0.299 \\
0.40 & 0.40 & +0.253 & +0.116 & \checkmark & 0.552 & 0.299 \\
\midrule
\multicolumn{7}{l}{\textit{Summary (all 25 configurations):}} \\
\multicolumn{2}{l}{Ranking preserved} & \multicolumn{5}{c}{100\% (25/25)} \\
\multicolumn{2}{l}{Min extreme greed gap} & \multicolumn{5}{c}{+0.239} \\
\multicolumn{2}{l}{Max extreme greed gap} & \multicolumn{5}{c}{+0.260} \\
\bottomrule
\end{tabular}
\end{adjustbox}
\vspace{0.3em}
\caption*{\footnotesize Selected rows from 25-configuration grid. ``Ranking preserved'' = extreme $>$ neutral in both greed and fear regimes. Full results available in repository.}
\end{table}

\subsection{Monte Carlo Weight Robustness}

Table~\ref{tab:mc_robustness_appendix} summarizes 1,000 Monte Carlo draws from Dirichlet(1,1,1,1), testing whether the extremity premium holds under random weight specifications.

\begin{table}[h!]
\centering
\caption{Monte Carlo Weight Robustness (1,000 Dirichlet Draws)}
\label{tab:mc_robustness_appendix}
\begin{tabular}{@{}lr@{}}
\toprule
\textbf{Metric} & \textbf{Value} \\
\midrule
Monte Carlo simulations & 1,000 \\
Dirichlet concentration & $(1, 1, 1, 1)$ \\
Extremity premium preserved & 100.0\% \\
95\% CI lower bound & 99.6\% \\
95\% CI upper bound & 100.0\% \\
Failures (greed $<$ neutral) & 0 \\
Failures (fear $<$ neutral) & 0 \\
\bottomrule
\end{tabular}
\vspace{0.3em}
\caption*{\footnotesize Dirichlet(1,1,1,1) is uniform over the probability simplex, generating maximally random weight combinations. Zero failures across 1,000 draws indicates the extremity premium is parameter-invariant.}
\end{table}

\subsection{GMM Weight Estimates}

Table~\ref{tab:gmm_appendix} reports GMM-estimated weights targeting four moments, with bootstrap standard errors.

\begin{table}[h!]
\centering
\caption{GMM Weight Estimates with Bootstrap Inference}
\label{tab:gmm_appendix}
\small
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{@{}lcccccc@{}}
\toprule
\textbf{Parameter} & \textbf{Estimate} & \textbf{SE} & \textbf{Heuristic} & \textbf{Diff} & \textbf{Boot SE} & \textbf{95\% CI} \\
\midrule
$w_{\text{aleatoric}}$ & 0.010 & 0.508 & 0.35 & $-$0.34 & 0.38 & [0.01, 0.98] \\
$w_{\text{epistemic}}$ & 0.322 & 15.94 & 0.30 & +0.02 & 0.28 & [0.01, 0.98] \\
$w_{\text{volatility}}$ & 0.668 & 33.04 & 0.35 & +0.32 & 0.37 & [0.01, 0.98] \\
\bottomrule
\end{tabular}
\end{adjustbox}
\vspace{0.3em}
\caption*{\footnotesize GMM targets: mean uncertainty, uncertainty SD, extreme greed gap, extreme fear gap. Wide bootstrap CIs indicate weak identification---multiple weight specifications are observationally equivalent. Heuristic weights fall within all CIs.}
\end{table}

\subsection{Normalization Robustness}

Table~\ref{tab:norm_appendix} compares the extremity premium across normalization methods.

\begin{table}[h!]
\centering
\caption{Normalization Robustness: Full-Sample vs Expanding-Window vs Rolling}
\label{tab:norm_appendix}
\begin{adjustbox}{max width=\textwidth}
\begin{tabular}{@{}lcccccc@{}}
\toprule
\textbf{Method} & \textbf{N} & \textbf{Greed Gap} & \textbf{Fear Gap} & \textbf{Premium?} & \textbf{$p$-value} \\
\midrule
Full-sample & 715 & +0.250 & +0.117 & Yes & $<$0.001 \\
Expanding-window & 685 & +0.353 & +0.173 & Yes & $<$0.001 \\
Rolling (90-day) & 686 & +0.330 & +0.266 & Yes & $<$0.001 \\
\bottomrule
\end{tabular}
\end{adjustbox}
\vspace{0.3em}
\caption*{\footnotesize All three normalization approaches preserve the extremity premium. Expanding-window and rolling methods produce larger gaps, suggesting full-sample estimates are conservative.}
\end{table}

\subsection{Variance Decomposition}

Table~\ref{tab:var_decomp_appendix} decomposes $R^2$ by predictor source.

\begin{table}[h!]
\centering
\caption{Variance Decomposition: $R^2$ by Predictor Source}
\label{tab:var_decomp_appendix}
\begin{tabular}{@{}lcc@{}}
\toprule
\textbf{Model} & \textbf{$R^2$} & \textbf{Incremental $R^2$} \\
\midrule
Volatility only & 0.755 & --- \\
+ Regime dummies & 0.768 & +0.013 \\
Regimes only (no volatility) & 0.198 & --- \\
\bottomrule
\end{tabular}
\vspace{0.3em}
\caption*{\footnotesize Volatility explains 75.5\% of uncertainty variance. Regime dummies add 1.3\% incremental $R^2$ after volatility control. Regimes alone explain only 19.8\%, confirming volatility dominates but regimes capture orthogonal variation.}
\end{table}

% ============================================================================
% DECLARATIONS
% ============================================================================
\section*{Declarations}

\subsection*{Funding}
No external funding was received for this research.

\subsection*{Conflict of Interest}
The author declares no conflicts of interest.

\subsection*{Data Availability}
The Crypto Fear \& Greed Index data are publicly available from Alternative.me. Binance OHLCV data are publicly available via the Binance API. Processed datasets used in the analysis are available from the author upon reasonable request.

\subsection*{Code Availability}
The agent-based model implementation, calibration scripts, and figure generation code are available at \url{https://github.com/studiofarzulla/sentiment-microstructure-abm}.

\end{document}
